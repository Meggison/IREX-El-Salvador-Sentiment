{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAUW9peEVwSM"
      },
      "source": [
        "# 1-Libraries and Dataset downloading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q dagshub\n",
        "!pip install transformers\n",
        "!pip install langchain_community\n",
        "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
        "!pip install OpenAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruCo1QvGNgJy",
        "outputId": "4be04f03-6b09-41fa-9e04-c97f1d417e81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kw8eiZl5rnKS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import time\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from transformers import BertTokenizer\n",
        "PRETRAINED_LM = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_LM, do_lower_case=True)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "import re\n",
        "from langchain import PromptTemplate\n",
        "from langchain.tools import BaseTool\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will prompt for authorization to access your Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_JO9B_TcMcW",
        "outputId": "cdc8118f-e52f-40d0-b4e4-027401b77b5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ObvZ-SAc9lsA"
      },
      "outputs": [],
      "source": [
        "file_path_train = '/content/drive/My Drive/Omdena/Sentiment_Analysis/tweets_spanish_train.csv'\n",
        "file_path_test = '/content/drive/My Drive/Omdena/Sentiment_Analysis/sentiment_beto_sample_bukele.xlsx'\n",
        "df_train = pd.read_csv(file_path_train)\n",
        "df_test=pd.read_excel(file_path_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u1dCiXyZ-aMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d364348e-188f-4e55-b4b5-5aedc782f7c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fu88hru8_WOM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f4238001-b8a3-4926-e3d1-0ac0c3086332"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Post Type                                               Text   AP  \\\n",
              "0  Astronaut Post         Dios lo bendiga por ser un gran ser humano  POS   \n",
              "1  Astronaut Post  Me encanta la humanidad de nuestro astronauta,...  POS   \n",
              "2  Astronaut Post  Dos grandes hombres haciendo historia. Gracias...  POS   \n",
              "3  Astronaut Post  Nayib y Frank dos grandes ejemplo de umildad y...  POS   \n",
              "4  Astronaut Post  A Colombia  le falta  un precidente  con este ...  NEU   \n",
              "\n",
              "  AP + JA Revised  \n",
              "0             POS  \n",
              "1             POS  \n",
              "2             POS  \n",
              "3             POS  \n",
              "4             POS  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3a13fd9-4381-445c-bb25-a5444b71ef12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post Type</th>\n",
              "      <th>Text</th>\n",
              "      <th>AP</th>\n",
              "      <th>AP + JA Revised</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Astronaut Post</td>\n",
              "      <td>Dios lo bendiga por ser un gran ser humano</td>\n",
              "      <td>POS</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Astronaut Post</td>\n",
              "      <td>Me encanta la humanidad de nuestro astronauta,...</td>\n",
              "      <td>POS</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Astronaut Post</td>\n",
              "      <td>Dos grandes hombres haciendo historia. Gracias...</td>\n",
              "      <td>POS</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Astronaut Post</td>\n",
              "      <td>Nayib y Frank dos grandes ejemplo de umildad y...</td>\n",
              "      <td>POS</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Astronaut Post</td>\n",
              "      <td>A Colombia  le falta  un precidente  con este ...</td>\n",
              "      <td>NEU</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3a13fd9-4381-445c-bb25-a5444b71ef12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3a13fd9-4381-445c-bb25-a5444b71ef12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3a13fd9-4381-445c-bb25-a5444b71ef12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-63696e54-c1ab-42ba-921d-0ab0d56a1de8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63696e54-c1ab-42ba-921d-0ab0d56a1de8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-63696e54-c1ab-42ba-921d-0ab0d56a1de8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 333,\n  \"fields\": [\n    {\n      \"column\": \"Post Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Astronaut Post\",\n          \"Reel\",\n          \"Google en El Salvador\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 331,\n        \"samples\": [\n          \"Que Admirables 2 seres  humanos Extraordinarios Y Salvadore\\u00f1os Humildes, Inteligentes, Brillantes. Que orgullo ser Salvadore\\u00f1a tuve el honor de saludar al Astronauta Frank Rubio est\\u00e1 semana por all\\u00ed me lo encontr\\u00e9. Saludos para los 2. Bendiciones\",\n          \"El mejor presidente que existe !!\\nNecesitamos un presidente como usted aqu\\u00ed en Per\\u00fa,  ya que  cada vez se hunde este pa\\u00eds,  por que  la corrupci\\u00f3n en imparable\",\n          \"Sara Cespedes muchas gracias por esas hermosas palabras saludos hasta Australia \\u2764\\ufe0f\\u2764\\ufe0f que Dios bendiga asu pa\\u00eds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AP\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"POS\",\n          \"NEU\",\n          \"NEG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AP + JA Revised\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"POS\",\n          \"NEU\",\n          \"NEG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xCo8QS4i-i87"
      },
      "outputs": [],
      "source": [
        "# Create a mapping dictionary to streamline LLM classification\n",
        "sentiment_train_mapping = {\n",
        "    'positive': 1,\n",
        "    'neutral': 0,\n",
        "    'negative': -1\n",
        "}\n",
        "\n",
        "sentiment_test_mapping = {\n",
        "    'POS': 1,\n",
        "    'NEU': 0,\n",
        "    'NEG': -1\n",
        "}\n",
        "\n",
        "# Apply the mapping to the 'sentiment' column\n",
        "df_train['sentiment'] = df_train['label'].map(sentiment_train_mapping)\n",
        "df_test['sentiment_revised'] = df_test['AP + JA Revised'].map(sentiment_test_mapping)\n",
        "df_test['sentiment'] = df_test['AP'].map(sentiment_test_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N12KmVVpV2R1"
      },
      "source": [
        "#2-CoT Agentic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2le4glJFcaSJ"
      },
      "outputs": [],
      "source": [
        "class WrapperFrame_v1:\n",
        "    def __init__(self, client):\n",
        "        self.client = client\n",
        "\n",
        "class Sentiment_Agent(WrapperFrame_v1):\n",
        "    def __init__(self, client):\n",
        "        super().__init__(client)\n",
        "\n",
        "        self.sentiment_agent = \"\"\"\n",
        "\n",
        "You are an AI language model trained to analyze and classify tweets {tweet} about El Salvador.\n",
        "Your job is to categorize each tweet into one of three categories based on its sentiment: 1 (positive), 0 (neutral), or -1 (negative) using a\n",
        "local Perspective from El salvador political scene.\n",
        "\n",
        "Guidelines:\n",
        ". 1 (Positive): The tweet expresses a positive sentiment, such as happiness, praise, or admiration.\n",
        ". 0 (Neutral): The tweet is neutral,. It may present facts, ask questions, or be generally balanced in tone or a statement or just mention a fact or a name.\n",
        ".-1 (Negative): The tweet expresses a negative sentiment, such as criticism, disappointment, or disapproval.\n",
        "\n",
        "Examples for Reference:\n",
        "\n",
        "1 (POS):\n",
        ". Tweet: \"Dios lo bendiga por ser un gran ser humano.\"\n",
        "   - Reasoning: The tweet is praising and expressing positive feelings towards someone.\n",
        "\n",
        ". Tweet: \"Me encanta la humanidad de nuestro astronauta, un hombre con gran corazón.\"\n",
        "   - Reasoning: The tweet shows love and admiration for the astronaut.\n",
        "\n",
        ". Tweet: \"Dos grandes hombres haciendo historia. Gracias por todo.\"\n",
        "   - Reasoning: The tweet appreciates the actions of two men, showing gratitude and positivity.\n",
        "\n",
        "0 (NEU):\n",
        ". Tweet: \"Tweet Maria Alicia Alas Moreno \"\n",
        "   - Reasoning:The tweet states a fact about the need for a certain type of president without strong positive or negative sentiment.\n",
        "\n",
        ". Tweet: \"Tweet Nuestros obstaculos son mentales\"\n",
        "   - Reasoning: The tweet presents a factual statement about the astronaut's activities without expressing an opinion.\n",
        "\n",
        ". Tweet: \"¿Qué opinan sobre las últimas noticias del presidente?\"\n",
        "   - Reasoning: The tweet is asking a question and does not convey a positive or negative sentiment.\n",
        "\n",
        "-1 (NEG):\n",
        ". Tweet: \"No estoy de acuerdo con las políticas actuales.\"\n",
        "   - Reasoning: The tweet expresses disagreement with current policies, indicating a negative sentiment.\n",
        "\n",
        ". Tweet: \"Es una vergüenza que esto esté sucediendo en nuestro país.\"\n",
        "   - Reasoning: The tweet expresses disappointment and criticism about a situation in the country.\n",
        "\n",
        ". Tweet: \"Las decisiones del presidente están dañando la economía.\"\n",
        "   - Reasoning: The tweet criticizes the president's decisions, showing a negative sentiment about their impact on the economy.\n",
        "\n",
        "\n",
        "    Instructions:\n",
        "\n",
        "      -Read the tweet carefully.\n",
        "\n",
        "      - Determine the sentiment expressed based on the content, using the following definitions and references:\n",
        "\n",
        "      - Generate a Json output followin this pattern:\n",
        "\n",
        "              (\n",
        "                \"classification\": 1,0,-1.\n",
        "                \"reasoning: reasoning of the answer in 50 words.\n",
        "              ).\n",
        "\n",
        "        \"\"\"\n",
        "        self.prompt_sentiment_agent = PromptTemplate(template=self.sentiment_agent, input_variables=[\"tweet\"])\n",
        "\n",
        "        # Corrected the LLMChain instantiation\n",
        "        self.llm_chain_sentiment_agent = LLMChain(prompt=self.prompt_sentiment_agent, llm=self.client)\n",
        "\n",
        "    def run_agent(self,tweet):\n",
        "        self.tweet = tweet\n",
        "\n",
        "        try:\n",
        "            sentiment_output = self.llm_chain_sentiment_agent.run({\"tweet\": self.tweet})\n",
        "            return sentiment_output\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            return \"Error sentiment agent\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5mP0YnyYIoZI"
      },
      "outputs": [],
      "source": [
        "class EvaluationProcessPipeline:\n",
        "\n",
        "    def __init__(self, client, row):\n",
        "        self.client = client\n",
        "        self.row = row\n",
        "        self.text = self.row[\"Text\"]\n",
        "        self.agent = Sentiment_Agent(self.client)\n",
        "\n",
        "    def process_tweet(self):\n",
        "        max_attempts = 1  # Define maximum number of retry attempts\n",
        "        attempts = 0\n",
        "\n",
        "        while attempts < max_attempts:\n",
        "            try:\n",
        "                # Run the selected Agent\n",
        "                entry_result = self.agent.run_agent(self.text)\n",
        "                print(\"Raw entry_result:\", entry_result)  # Debugging line to see what is being returned\n",
        "\n",
        "                # Attempt to parse the JSON data\n",
        "                data = json.loads(entry_result)\n",
        "                labels = data[\"classification\"]\n",
        "                print(\"Extracted labels:\", labels)  # Debugging line to confirm label extraction\n",
        "                return labels  # Successful parsing and return, exit loop\n",
        "            except (json.JSONDecodeError, Exception) as error:\n",
        "                # Handle both JSON parsing errors and other exceptions\n",
        "                print(f\"Error encountered (attempt {attempts + 1}):\", error)\n",
        "                attempts += 1\n",
        "                time.sleep(1)  # Sleep before retrying\n",
        "\n",
        "        print(\"Failed after\", max_attempts, \"attempts.\")\n",
        "        return []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL2UNuAU_Y3V"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HZ6Ks88BJ5hB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d14e6b-ab0c-42c9-9275-0bb4d83a01ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6AEi_DfUx4A"
      },
      "source": [
        "\n",
        "\n",
        "#2.1- Inference Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NCZ1b_JuaQCf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lifEXk3iFCYs"
      },
      "outputs": [],
      "source": [
        "predicted_values=[]\n",
        "real_values_revised=[]\n",
        "for i,entry in enumerate (df_test.loc[:,'Text']):\n",
        "    print(i)\n",
        "    agent = EvaluationProcessPipeline(llm, df_test.iloc[i])\n",
        "    print('Tweet',df_test.loc[i,'Text'])\n",
        "    label = agent.process_tweet()\n",
        "    predicted_values.append(label)\n",
        "    real_values_revised.append(df_test.iloc[i]['sentiment_revised'])\n",
        "    print('Real Value Revisited',df_test.iloc[i]['sentiment_revised'])\n",
        "    time.sleep(1)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}