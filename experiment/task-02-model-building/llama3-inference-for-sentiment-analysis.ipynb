{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8805116,"sourceType":"datasetVersion","datasetId":5295556},{"sourceId":33551,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":28083}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport transformers\nimport json","metadata":{"execution":{"iopub.status.busy":"2024-06-27T20:55:19.425517Z","iopub.execute_input":"2024-06-27T20:55:19.426140Z","iopub.status.idle":"2024-06-27T20:55:23.792721Z","shell.execute_reply.started":"2024-06-27T20:55:19.426105Z","shell.execute_reply":"2024-06-27T20:55:23.791708Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/labeled-data/train_df_2100_manual_final.csv\")\ndf_val = pd.read_csv(\"/kaggle/input/labeled-data/validation_df_450_manual_final.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/labeled-data/test_df_450_manual_final.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-27T20:55:23.793974Z","iopub.execute_input":"2024-06-27T20:55:23.794409Z","iopub.status.idle":"2024-06-27T20:55:23.945219Z","shell.execute_reply.started":"2024-06-27T20:55:23.794382Z","shell.execute_reply":"2024-06-27T20:55:23.944412Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=checkpoint,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T20:55:23.946622Z","iopub.execute_input":"2024-06-27T20:55:23.946902Z","iopub.status.idle":"2024-06-27T20:56:23.895571Z","shell.execute_reply.started":"2024-06-27T20:55:23.946877Z","shell.execute_reply":"2024-06-27T20:56:23.894633Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-27 20:55:26.106619: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-27 20:55:26.106720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-27 20:55:26.283132: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f846cac055c4078b91ccc4b2495ffdf"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-27T20:56:23.898531Z","iopub.execute_input":"2024-06-27T20:56:23.899340Z","iopub.status.idle":"2024-06-27T20:56:23.906532Z","shell.execute_reply.started":"2024-06-27T20:56:23.899295Z","shell.execute_reply":"2024-06-27T20:56:23.905527Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"json_schema = {\"classification\": \"classification value between 1, 0, -1\",\n              \"explanation\": \"reasoning of the answer in 50 words\"}\n\ninput_tweet = \"Pongase serio Nayib Bukele  no nos venga con esa ud bien save que nadie a salido al espacio\"\n\nsystem_message = \"\"\"You are an AI assistant designed to answer simple questions.\nPlease restrict your answer to the exact question asked and respond with a json object only.\n\"\"\"\n\nuser_message = f\"\"\"You are an AI language model trained to analyze tweets and comments from the people of the country of El Salvador.\n    Your job is to categorize each tweet into one of three categories based on its sentiment: 1 (positive), 0 (neutral), or -1 (negative) using a\n    local perspective from El salvador political scene.\n\n    Guidelines:\n    . 1 (Positive): The tweet expresses a positive sentiment, such as happiness, praise, appreciation or admiration. Be careful of the use of sarcasm and avoid classifying sarcastic tweets as positive\n    . 0 (Neutral): The tweet is neutral,. It may present facts, ask questions, or be generally balanced in tone or a statement or just mention a fact or a name.\n    .-1 (Negative): The tweet expresses a negative sentiment, such as criticism, disappointment, or disapproval. Classify sarcastic comments which actually have a negative sentiment here\n\n    Examples for Reference:\n\n    1 (POS):\n    . Tweet: \"Dios lo bendiga por ser un gran ser humano.\"\n    - Reasoning: The tweet is praising and expressing positive feelings towards someone.\n\n    . Tweet: \"Me encanta la humanidad de nuestro astronauta, un hombre con gran corazón.\"\n    - Reasoning: The tweet shows love and admiration for the astronaut.\n\n    . Tweet: \"Dos grandes hombres haciendo historia. Gracias por todo.\"\n    - Reasoning: The tweet appreciates the actions of two men, showing gratitude and positivity.\n\n    0 (NEU):\n    . Tweet: \"Tweet Maria Alicia Alas Moreno \"\n    - Reasoning:The tweet states a fact about the need for a certain type of president without strong positive or negative sentiment.\n\n    . Tweet: \"Tweet Nuestros obstaculos son mentales\"\n    - Reasoning: The tweet presents a factual statement about the astronaut's activities without expressing an opinion.\n\n    . Tweet: \"¿Qué opinan sobre las últimas noticias del presidente?\"\n    - Reasoning: The tweet is asking a question and does not convey a positive or negative sentiment.\n\n    -1 (NEG):\n    . Tweet: \"No estoy de acuerdo con las políticas actuales.\"\n    - Reasoning: The tweet expresses disagreement with current policies, indicating a negative sentiment.\n\n    . Tweet: \"Es una vergüenza que esto esté sucediendo en nuestro país.\"\n    - Reasoning: The tweet expresses disappointment and criticism about a situation in the country.\n\n    . Tweet: \"Las decisiones del presidente están dañando la economía.\"\n    - Reasoning: The tweet criticizes the president's decisions, showing a negative sentiment about their impact on the economy.\n    Instructions:\n        \n        - Read the tweet carefully.\n\n        - Determine the sentiment expressed based on your expertise, the guidelines and examples provided above:\n\n        - Generate a json output following the json schema:\n    \n    Tweet: {input_tweet}\n    Json Schema: {json_schema}\n    Your Answer: \"\"\"\n\nmessages = [\n    {\"role\": \"system\", \"content\": system_message},\n    {\"role\": \"user\", \"content\": user_message},\n]\n\nprompt = pipeline.tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize = False)\n\nterminators = [\n        pipeline.tokenizer.eos_token_id,\n        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n    ]\n\nmax_length=256\ntemperature = 0.1\n\nresponse = pipeline(prompt,\n#                    do_samples=True,\n#                    top_p=0.9,\n        temperature=temperature,\n#         num_return_sequences=1,\n        eos_token_id=terminators,\n        max_new_tokens=max_length,\n        return_full_text=False,\n                    repetition_penalty=1.0\n#         pad_token_id=pipeline.model.config.eos_token_id\n                   )","metadata":{"execution":{"iopub.status.busy":"2024-06-27T20:56:23.907696Z","iopub.execute_input":"2024-06-27T20:56:23.907995Z","iopub.status.idle":"2024-06-27T20:56:29.043813Z","shell.execute_reply.started":"2024-06-27T20:56:23.907970Z","shell.execute_reply":"2024-06-27T20:56:29.042884Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"response","metadata":{"execution":{"iopub.status.busy":"2024-06-27T20:56:29.045109Z","iopub.execute_input":"2024-06-27T20:56:29.045667Z","iopub.status.idle":"2024-06-27T20:56:29.051519Z","shell.execute_reply.started":"2024-06-27T20:56:29.045638Z","shell.execute_reply":"2024-06-27T20:56:29.050547Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': '{\\n\"classification\": -1,\\n\"explanation\": \"The tweet expresses a negative sentiment towards Nayib Bukele, criticizing him for not being serious and making false claims about space travel, indicating a negative sentiment towards his leadership.\"\\n}'}]"},"metadata":{}}]},{"cell_type":"code","source":"json.loads(response[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:31:46.064839Z","iopub.execute_input":"2024-06-27T21:31:46.065290Z","iopub.status.idle":"2024-06-27T21:31:46.072038Z","shell.execute_reply.started":"2024-06-27T21:31:46.065254Z","shell.execute_reply":"2024-06-27T21:31:46.071130Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"{'classification': -1,\n 'explanation': 'The tweet expresses a negative sentiment towards Nayib Bukele, criticizing him for not being serious and making false claims about space travel, indicating a negative sentiment towards his leadership.'}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Deployment Code","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport transformers\nimport json\nimport time\n\nclass TweetClassifier:\n    def __init__(self, model_checkpoint):\n        self.pipeline = transformers.pipeline(\n            \"text-generation\",\n            model=model_checkpoint,\n            torch_dtype=torch.float16,\n            device_map=\"auto\",\n        )\n        self.system_message = \"\"\"You are an AI assistant designed to answer simple questions.\nPlease restrict your answer to the exact question asked and respond with a json object only.\n\"\"\"\n        self.json_schema = {\n            \"classification\": \"classification value between 1, 0, -1\",\n            \"explanation\": \"reasoning of the answer in 50 words\"\n        }\n\n    def create_prompt(self, tweet):\n        user_message = f\"\"\"You are an AI language model trained to analyze tweets and comments from the people of the country of El Salvador.\n    Your job is to categorize each tweet into one of three categories based on its sentiment: 1 (positive), 0 (neutral), or -1 (negative) using a\n    local perspective from El salvador political scene.\n\n    Guidelines:\n    . 1 (Positive): The tweet expresses a positive sentiment, such as happiness, praise, appreciation or admiration. Be careful of the use of sarcasm and avoid classifying sarcastic tweets as positive\n    . 0 (Neutral): The tweet is neutral,. It may present facts, ask questions, or be generally balanced in tone or a statement or just mention a fact or a name.\n    .-1 (Negative): The tweet expresses a negative sentiment, such as criticism, disappointment, or disapproval. Classify sarcastic comments which actually have a negative sentiment here\n\n    Examples for Reference:\n\n    1 (POS):\n    . Tweet: \"Dios lo bendiga por ser un gran ser humano.\"\n    - Reasoning: The tweet is praising and expressing positive feelings towards someone.\n\n    . Tweet: \"Me encanta la humanidad de nuestro astronauta, un hombre con gran corazón.\"\n    - Reasoning: The tweet shows love and admiration for the astronaut.\n\n    . Tweet: \"Dos grandes hombres haciendo historia. Gracias por todo.\"\n    - Reasoning: The tweet appreciates the actions of two men, showing gratitude and positivity.\n\n    0 (NEU):\n    . Tweet: \"Tweet Maria Alicia Alas Moreno \"\n    - Reasoning:The tweet states a fact about the need for a certain type of president without strong positive or negative sentiment.\n\n    . Tweet: \"Tweet Nuestros obstaculos son mentales\"\n    - Reasoning: The tweet presents a factual statement about the astronaut's activities without expressing an opinion.\n\n    . Tweet: \"¿Qué opinan sobre las últimas noticias del presidente?\"\n    - Reasoning: The tweet is asking a question and does not convey a positive or negative sentiment.\n\n    -1 (NEG):\n    . Tweet: \"No estoy de acuerdo con las políticas actuales.\"\n    - Reasoning: The tweet expresses disagreement with current policies, indicating a negative sentiment.\n\n    . Tweet: \"Es una vergüenza que esto esté sucediendo en nuestro país.\"\n    - Reasoning: The tweet expresses disappointment and criticism about a situation in the country.\n\n    . Tweet: \"Las decisiones del presidente están dañando la economía.\"\n    - Reasoning: The tweet criticizes the president's decisions, showing a negative sentiment about their impact on the economy.\n    Instructions:\n        \n        - Read the tweet carefully.\n\n        - Determine the sentiment expressed based on your expertise, the guidelines and examples provided above:\n\n        - Generate a json output following the json schema:\n    \n    Tweet: {tweet}\n    Json Schema: {json_schema}\n    Your Answer: \"\"\"\n\n        messages = [\n            {\"role\": \"system\", \"content\": self.system_message},\n            {\"role\": \"user\", \"content\": user_message},\n        ]\n        \n        prompt = self.pipeline.tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n        \n        return prompt\n\n    def classify_tweet(self, tweet):\n        prompt = self.create_prompt(tweet)\n        terminators = [\n            self.pipeline.tokenizer.eos_token_id,\n            self.pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n        ]\n        max_length = 256\n        temperature = 0.1\n        \n        \n        attempts = 0\n        max_attempts = 1\n        \n        while max_attempts > attempts:\n            try:\n                \n                response = self.pipeline(\n                    prompt,\n#                     temperature=temperature,\n                    eos_token_id=terminators,\n                    max_new_tokens=max_length,\n                    return_full_text=False,\n                    repetition_penalty=1.0\n                )\n                result = json.loads(response[0]['generated_text'])\n                \n                return result['classification'], result['explanation']\n            except (json.JSONDecodeError, Exception) as error:\n                print(f\"Error encountered (attempt {attempts + 1}):\", error)\n                attempts += 1\n                time.sleep(1)  # Sleep before retrying\n                    \n                return 0, \"Error in json parsing\"\n        \n\n    def process_dataframe(self, df):\n        classifications = []\n        explanations = []\n        for index, row in df.iterrows():\n            tweet = row['tweet']\n            classification, explanation = self.classify_tweet(tweet)\n            classifications.append(classification)\n            explanations.append(explanation)\n        df['classification'] = pd.Series(classifications)\n        df['explanation'] = pd.Series(explanations)\n\n        return df\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:25:51.931883Z","iopub.execute_input":"2024-06-27T21:25:51.932845Z","iopub.status.idle":"2024-06-27T21:25:51.949294Z","shell.execute_reply.started":"2024-06-27T21:25:51.932808Z","shell.execute_reply":"2024-06-27T21:25:51.948477Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Usage\nif __name__ == \"__main__\":\n    df_test = pd.read_csv(\"/kaggle/input/labeled-data/test_df_450_manual_final.csv\")\n    df_test.rename(columns = {'comment_processed_text': 'tweet'}, inplace=True)\n    model_checkpoint = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n\n    classifier = TweetClassifier(model_checkpoint)\n    df_result = classifier.process_dataframe(df_test.sample(10))\n    \n    df_result.to_csv(\"classified_tweets.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:26:04.737251Z","iopub.execute_input":"2024-06-27T21:26:04.737612Z","iopub.status.idle":"2024-06-27T21:26:52.803360Z","shell.execute_reply.started":"2024-06-27T21:26:04.737579Z","shell.execute_reply":"2024-06-27T21:26:52.802488Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a027506496e04e7b95dfa8dcaf15f121"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.96 GiB is allocated by PyTorch, and 708.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.96 GiB is allocated by PyTorch, and 705.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.96 GiB is allocated by PyTorch, and 704.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.98 GiB is allocated by PyTorch, and 688.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.99 GiB is allocated by PyTorch, and 680.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.97 GiB is allocated by PyTorch, and 702.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.96 GiB is allocated by PyTorch, and 705.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.96 GiB is allocated by PyTorch, and 708.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.98 GiB is allocated by PyTorch, and 693.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error encountered (attempt 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 991.06 MiB is free. Process 45429 has 13.78 GiB memory in use. Of the allocated memory 12.99 GiB is allocated by PyTorch, and 679.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"}]},{"cell_type":"code","source":"df_result","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:18:54.274481Z","iopub.execute_input":"2024-06-27T21:18:54.274809Z","iopub.status.idle":"2024-06-27T21:18:54.313588Z","shell.execute_reply.started":"2024-06-27T21:18:54.274779Z","shell.execute_reply":"2024-06-27T21:18:54.312579Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"     Unnamed: 0.1  Unnamed: 0  \\\n136           728        2248   \n0            2621        8340   \n179           674        1946   \n433          1201        3892   \n119          1061        3459   \n402          2776        8710   \n392           815        2608   \n409          2377        7702   \n411          2193        6968   \n445          2443        7979   \n\n                                           comment_url  comment_createdAt  \\\n136  https://x.com/cesarcortezfoto/status/175132929...       1.706384e+09   \n0      https://x.com/az75de/status/1299484106313682947       1.598656e+09   \n179  https://x.com/MGo24332752/status/1759375768755...       1.708303e+09   \n433  https://x.com/MariaLuisaHayem/status/131791778...       1.603051e+09   \n119  https://x.com/DobleH1994/status/14771509984184...       1.641015e+09   \n402  https://x.com/Heriberto__Es/status/16607477273...       1.684788e+09   \n392  https://x.com/Lopez99715323/status/12309280493...       1.582311e+09   \n409  https://x.com/GuevaDave2108/status/17635813739...       1.709306e+09   \n411  https://x.com/DelmerZavala2/status/13916304377...       1.620626e+09   \n445  https://x.com/DerekSm18831275/status/178149528...       1.713577e+09   \n\n       comment_id  comment_viewCount comment_lang comment_author_createdAt  \\\n136  1.751330e+18               16.0           es               16/01/2018   \n0    1.299480e+18                NaN           es               30/03/2020   \n179  1.759380e+18                4.0           es               30/08/2023   \n433  1.317920e+18                NaN           es               05/06/2019   \n119  1.477150e+18                NaN           es               30/09/2011   \n402  1.660750e+18              588.0           es               16/08/2017   \n392  1.230930e+18                NaN           es               03/09/2018   \n409  1.763580e+18                3.0           es               05/08/2023   \n411  1.391630e+18                NaN           es               01/10/2017   \n445  1.781500e+18               35.0           es               15/12/2019   \n\n                   comment_location  \\\n136                          Canada   \n0                               NaN   \n179                             NaN   \n433                     El Salvador   \n119                           Sivar   \n402     Ex Republica de El Salvador   \n392  El Salvador, Zona Paracentral.   \n409                             NaN   \n411                        Honduras   \n445                             NaN   \n\n                                          comment_text  ...  post_verified  \\\n136  @PulsoCiudadanos @Cerg89 @ARENAOFICIAL En qué ...  ...           True   \n0    @FranAlabi @grupo_samu 👏🏼👏🏼👏🏼👏🏼👏🏼👏🏼👏🏼👏🏼Dios lo...  ...           True   \n179  @MarceloLarin1 Larin deja de fumar 🚬  delirios...  ...           True   \n433  Nuestro Presidente @NayibBukele ha hecho una a...  ...          False   \n119   @easegura He aquí la definición de gata angora 🤦  ...          False   \n402  @FranAlabi Asi como despidieron a las dras, es...  ...           True   \n392  @ChristianR117 @chelita_NI @nayibbukele Es una...  ...          False   \n409              @MarceloLarin1 Que te importa seroton  ...           True   \n411  @FranAlabi @nayibbukele El pueblo Hondureño es...  ...           True   \n445  @MarceloLarin1 Hay chats del marcelo Con gente...  ...           True   \n\n                                             post_text  \\\n136  #PulsoCiudadano 🗣️| “Yo nací en democracia, cr...   \n0    \"Nos abrazaste, no pudiste, pero nos abrazaste...   \n179  Me asombra que aunque el gobierno hizo gran fr...   \n433  El #DespegueEconómico del país ya comenzó, las...   \n119  Honestamente, creo que no urgía hacer una bibl...   \n402  Pido disculpas a la población por mis declarac...   \n392  ⚠️ULTIMA HORA⚠️\\n\\nPresidente de El Salvador @...   \n409  Estimado Diputado Walter Aleman usted que opin...   \n411  La solidaridad es un valor que nos debe caract...   \n445  Walter araujo y Romeo Lemus al parecer quieren...   \n\n    isActor_self__decalred__location__El_Salvador  \\\n136                                          True   \n0                                            True   \n179                                         False   \n433                                          True   \n119                                          True   \n402                                          True   \n392                                          True   \n409                                         False   \n411                                          True   \n445                                         False   \n\n                                   post_processed_text      actor_affiliation  \\\n136  yo nací en democracia crecí en democracia y ju...                  Media   \n0    nos abrazaste no pudiste pero nos abrazaste he...             Government   \n179  me asombra que aunque el gobierno hizo gran fr...                  Media   \n433  el del país ya comenzó las calificadoras de ri...             Government   \n119  honestamente creo que no urgía hacer una bibli...  ['Media', 'Academia']   \n402  pido disculpas a la población por mis declarac...             Government   \n392  ultima hora presidente de el salvador somete a...                  Media   \n409  estimado diputado walter aleman usted que opin...                  Media   \n411  la solidaridad es un valor que nos debe caract...             Government   \n445  walter araujo y romeo lemus al parecer quieren...                  Media   \n\n     llama3_output                                      llama3_reason  \\\n136            0.0  The tweet is asking a question about the count...   \n0              0.0                                     row with error   \n179           -1.0  The tweet expresses a negative sentiment, crit...   \n433            1.0  The tweet expresses a positive sentiment as it...   \n119            0.0  The tweet presents a factual definition of 'ga...   \n402           -1.0  The tweet expresses a negative sentiment towar...   \n392            1.0  The tweet expresses a positive sentiment by me...   \n409            0.0  The tweet is neutral, as it is a question and ...   \n411            1.0  The tweet expresses gratitude and appreciation...   \n445            0.0  The tweet presents a factual statement about c...   \n\n     manual labeling  classification  \\\n136                0               0   \n0                  1               1   \n179               -1              -1   \n433                1               1   \n119                0               0   \n402               -1              -1   \n392               -1               0   \n409               -1               0   \n411                1               1   \n445                0               0   \n\n                                           explanation  \n136  The tweet is asking a question about someone's...  \n0    The tweet expresses a positive sentiment, as i...  \n179  The tweet expresses a negative sentiment, crit...  \n433  The tweet expresses a positive sentiment, prai...  \n119  The tweet presents a factual definition of a c...  \n402  The tweet expresses a negative sentiment, crit...  \n392  The tweet presents a factual statement about t...  \n409  The tweet is neutral, as it is a question and ...  \n411  The tweet expresses gratitude and appreciation...  \n445  The tweet presents a factual statement about c...  \n\n[10 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>comment_url</th>\n      <th>comment_createdAt</th>\n      <th>comment_id</th>\n      <th>comment_viewCount</th>\n      <th>comment_lang</th>\n      <th>comment_author_createdAt</th>\n      <th>comment_location</th>\n      <th>comment_text</th>\n      <th>...</th>\n      <th>post_verified</th>\n      <th>post_text</th>\n      <th>isActor_self__decalred__location__El_Salvador</th>\n      <th>post_processed_text</th>\n      <th>actor_affiliation</th>\n      <th>llama3_output</th>\n      <th>llama3_reason</th>\n      <th>manual labeling</th>\n      <th>classification</th>\n      <th>explanation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>136</th>\n      <td>728</td>\n      <td>2248</td>\n      <td>https://x.com/cesarcortezfoto/status/175132929...</td>\n      <td>1.706384e+09</td>\n      <td>1.751330e+18</td>\n      <td>16.0</td>\n      <td>es</td>\n      <td>16/01/2018</td>\n      <td>Canada</td>\n      <td>@PulsoCiudadanos @Cerg89 @ARENAOFICIAL En qué ...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>#PulsoCiudadano 🗣️| “Yo nací en democracia, cr...</td>\n      <td>True</td>\n      <td>yo nací en democracia crecí en democracia y ju...</td>\n      <td>Media</td>\n      <td>0.0</td>\n      <td>The tweet is asking a question about the count...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The tweet is asking a question about someone's...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2621</td>\n      <td>8340</td>\n      <td>https://x.com/az75de/status/1299484106313682947</td>\n      <td>1.598656e+09</td>\n      <td>1.299480e+18</td>\n      <td>NaN</td>\n      <td>es</td>\n      <td>30/03/2020</td>\n      <td>NaN</td>\n      <td>@FranAlabi @grupo_samu 👏🏼👏🏼👏🏼👏🏼👏🏼👏🏼👏🏼👏🏼Dios lo...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>\"Nos abrazaste, no pudiste, pero nos abrazaste...</td>\n      <td>True</td>\n      <td>nos abrazaste no pudiste pero nos abrazaste he...</td>\n      <td>Government</td>\n      <td>0.0</td>\n      <td>row with error</td>\n      <td>1</td>\n      <td>1</td>\n      <td>The tweet expresses a positive sentiment, as i...</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>674</td>\n      <td>1946</td>\n      <td>https://x.com/MGo24332752/status/1759375768755...</td>\n      <td>1.708303e+09</td>\n      <td>1.759380e+18</td>\n      <td>4.0</td>\n      <td>es</td>\n      <td>30/08/2023</td>\n      <td>NaN</td>\n      <td>@MarceloLarin1 Larin deja de fumar 🚬  delirios...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>Me asombra que aunque el gobierno hizo gran fr...</td>\n      <td>False</td>\n      <td>me asombra que aunque el gobierno hizo gran fr...</td>\n      <td>Media</td>\n      <td>-1.0</td>\n      <td>The tweet expresses a negative sentiment, crit...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>The tweet expresses a negative sentiment, crit...</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>1201</td>\n      <td>3892</td>\n      <td>https://x.com/MariaLuisaHayem/status/131791778...</td>\n      <td>1.603051e+09</td>\n      <td>1.317920e+18</td>\n      <td>NaN</td>\n      <td>es</td>\n      <td>05/06/2019</td>\n      <td>El Salvador</td>\n      <td>Nuestro Presidente @NayibBukele ha hecho una a...</td>\n      <td>...</td>\n      <td>False</td>\n      <td>El #DespegueEconómico del país ya comenzó, las...</td>\n      <td>True</td>\n      <td>el del país ya comenzó las calificadoras de ri...</td>\n      <td>Government</td>\n      <td>1.0</td>\n      <td>The tweet expresses a positive sentiment as it...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>The tweet expresses a positive sentiment, prai...</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>1061</td>\n      <td>3459</td>\n      <td>https://x.com/DobleH1994/status/14771509984184...</td>\n      <td>1.641015e+09</td>\n      <td>1.477150e+18</td>\n      <td>NaN</td>\n      <td>es</td>\n      <td>30/09/2011</td>\n      <td>Sivar</td>\n      <td>@easegura He aquí la definición de gata angora 🤦</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Honestamente, creo que no urgía hacer una bibl...</td>\n      <td>True</td>\n      <td>honestamente creo que no urgía hacer una bibli...</td>\n      <td>['Media', 'Academia']</td>\n      <td>0.0</td>\n      <td>The tweet presents a factual definition of 'ga...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The tweet presents a factual definition of a c...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>2776</td>\n      <td>8710</td>\n      <td>https://x.com/Heriberto__Es/status/16607477273...</td>\n      <td>1.684788e+09</td>\n      <td>1.660750e+18</td>\n      <td>588.0</td>\n      <td>es</td>\n      <td>16/08/2017</td>\n      <td>Ex Republica de El Salvador</td>\n      <td>@FranAlabi Asi como despidieron a las dras, es...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>Pido disculpas a la población por mis declarac...</td>\n      <td>True</td>\n      <td>pido disculpas a la población por mis declarac...</td>\n      <td>Government</td>\n      <td>-1.0</td>\n      <td>The tweet expresses a negative sentiment towar...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>The tweet expresses a negative sentiment, crit...</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>815</td>\n      <td>2608</td>\n      <td>https://x.com/Lopez99715323/status/12309280493...</td>\n      <td>1.582311e+09</td>\n      <td>1.230930e+18</td>\n      <td>NaN</td>\n      <td>es</td>\n      <td>03/09/2018</td>\n      <td>El Salvador, Zona Paracentral.</td>\n      <td>@ChristianR117 @chelita_NI @nayibbukele Es una...</td>\n      <td>...</td>\n      <td>False</td>\n      <td>⚠️ULTIMA HORA⚠️\\n\\nPresidente de El Salvador @...</td>\n      <td>True</td>\n      <td>ultima hora presidente de el salvador somete a...</td>\n      <td>Media</td>\n      <td>1.0</td>\n      <td>The tweet expresses a positive sentiment by me...</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>The tweet presents a factual statement about t...</td>\n    </tr>\n    <tr>\n      <th>409</th>\n      <td>2377</td>\n      <td>7702</td>\n      <td>https://x.com/GuevaDave2108/status/17635813739...</td>\n      <td>1.709306e+09</td>\n      <td>1.763580e+18</td>\n      <td>3.0</td>\n      <td>es</td>\n      <td>05/08/2023</td>\n      <td>NaN</td>\n      <td>@MarceloLarin1 Que te importa seroton</td>\n      <td>...</td>\n      <td>True</td>\n      <td>Estimado Diputado Walter Aleman usted que opin...</td>\n      <td>False</td>\n      <td>estimado diputado walter aleman usted que opin...</td>\n      <td>Media</td>\n      <td>0.0</td>\n      <td>The tweet is neutral, as it is a question and ...</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>The tweet is neutral, as it is a question and ...</td>\n    </tr>\n    <tr>\n      <th>411</th>\n      <td>2193</td>\n      <td>6968</td>\n      <td>https://x.com/DelmerZavala2/status/13916304377...</td>\n      <td>1.620626e+09</td>\n      <td>1.391630e+18</td>\n      <td>NaN</td>\n      <td>es</td>\n      <td>01/10/2017</td>\n      <td>Honduras</td>\n      <td>@FranAlabi @nayibbukele El pueblo Hondureño es...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>La solidaridad es un valor que nos debe caract...</td>\n      <td>True</td>\n      <td>la solidaridad es un valor que nos debe caract...</td>\n      <td>Government</td>\n      <td>1.0</td>\n      <td>The tweet expresses gratitude and appreciation...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>The tweet expresses gratitude and appreciation...</td>\n    </tr>\n    <tr>\n      <th>445</th>\n      <td>2443</td>\n      <td>7979</td>\n      <td>https://x.com/DerekSm18831275/status/178149528...</td>\n      <td>1.713577e+09</td>\n      <td>1.781500e+18</td>\n      <td>35.0</td>\n      <td>es</td>\n      <td>15/12/2019</td>\n      <td>NaN</td>\n      <td>@MarceloLarin1 Hay chats del marcelo Con gente...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>Walter araujo y Romeo Lemus al parecer quieren...</td>\n      <td>False</td>\n      <td>walter araujo y romeo lemus al parecer quieren...</td>\n      <td>Media</td>\n      <td>0.0</td>\n      <td>The tweet presents a factual statement about c...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The tweet presents a factual statement about c...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 38 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}