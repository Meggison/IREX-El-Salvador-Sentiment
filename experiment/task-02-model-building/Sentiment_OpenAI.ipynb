{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(r'C:\\Users\\DhalS\\OneDrive - Kantar\\Desktop\\Omdena\\IREX-El-Salvador-Sentiment\\experiment\\task-02-model-building\\train_df_2100_manual_final.csv')\n",
    "df_val = pd.read_csv(r'C:\\Users\\DhalS\\OneDrive - Kantar\\Desktop\\Omdena\\IREX-El-Salvador-Sentiment\\experiment\\task-02-model-building\\validation_df_450_manual_final.csv')\n",
    "df_test = pd.read_csv(r'C:\\Users\\DhalS\\OneDrive - Kantar\\Desktop\\Omdena\\IREX-El-Salvador-Sentiment\\experiment\\task-02-model-building\\test_df_450_manual_final.csv')\n",
    "\n",
    "\n",
    "\n",
    "total_df = pd.concat([df_train, df_val, df_test], axis=0)\n",
    "total_df.shape\n",
    "\n",
    "df_train.rename(columns={'manual labeling': 'manual_labeling'}, inplace=True)\n",
    "df_val.rename(columns={'manual labeling': 'manual_labeling'}, inplace=True)\n",
    "df_test.rename(columns={'manual labeling': 'manual_labeling'}, inplace=True)\n",
    "\n",
    "total_df.rename(columns={'manual labeling': 'manual_labeling'}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "# Set up your OpenAI API key\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['OPENAI_API_KEY'] = 'sk'\n",
    "\n",
    "# Verify if the environment variable is set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify if the environment variable is set\n",
    "#print(os.getenv('OPENAI_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Ensure the OpenAI API key is set\n",
    "\n",
    "# Define the function to get the sentiment response using zero-shot\n",
    "def get_response(example):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a sentiment analysis system. Analyze the sentiment of the given tweets or tweet comments and return one word: Positive, Negative, or Neutral.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{example}\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "example_review = \"The service was good but the food was bland and cold.\"\n",
    "print(get_response(example_review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Ensure the OpenAI API key is set\n",
    "\n",
    "# Define the function to get the sentiment response using zero-shot\n",
    "def get_response(example):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a sentiment analysis system. Analyze the sentiment of the given tweets or tweet replies in salvadorian spanish and return one word: Positive, Negative, or Neutral.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{example}\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "example_review = \"El servicio fue bueno pero la comida estaba insípida y fría.\"\n",
    "print(get_response(example_review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 36)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     uff lancha nueva\n",
       "1    es lo menos q podemos hacer despues de devolve...\n",
       "2    todavia lloras porque no te dieron un hueso en...\n",
       "3    lonque el no entiende es que si no hubiese hec...\n",
       "4    excelente muy bonito se ve lo público mejor qu...\n",
       "Name: comment_processed_text, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_processed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'comment_url', 'comment_createdAt',\n",
       "       'comment_id', 'comment_viewCount', 'comment_lang',\n",
       "       'comment_author_createdAt', 'comment_location', 'comment_text',\n",
       "       'isComment_self__decalred__location__El_Salvador',\n",
       "       'comment_processed_text', 'post_url', 'post_actor_createdAt', 'post_id',\n",
       "       'post_isReply', 'post_inReplyToId', 'post_isRetweet', 'post_isQuote',\n",
       "       'post_viewCount', 'post_retweetCount', 'post_likeCount',\n",
       "       'post_replyCount', 'post_lang', 'actor_location', 'post_name',\n",
       "       'post_description', 'post_followers', 'post_verified', 'post_text',\n",
       "       'isActor_self__decalred__location__El_Salvador', 'post_processed_text',\n",
       "       'actor_affiliation', 'llama3_output', 'llama3_reason',\n",
       "       'manual_labeling'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new column for sentiment labels\n",
    "df['open_ai_gpt4_base'] = df['comment_processed_text'].apply(get_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_url</th>\n",
       "      <th>comment_createdAt</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_viewCount</th>\n",
       "      <th>comment_lang</th>\n",
       "      <th>comment_author_createdAt</th>\n",
       "      <th>comment_location</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>...</th>\n",
       "      <th>post_followers</th>\n",
       "      <th>post_verified</th>\n",
       "      <th>post_text</th>\n",
       "      <th>isActor_self__decalred__location__El_Salvador</th>\n",
       "      <th>post_processed_text</th>\n",
       "      <th>actor_affiliation</th>\n",
       "      <th>llama3_output</th>\n",
       "      <th>llama3_reason</th>\n",
       "      <th>manual_labeling</th>\n",
       "      <th>open_ai_gpt4_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>532</td>\n",
       "      <td>1209</td>\n",
       "      <td>https://x.com/dany_u07/status/1773424640678838281</td>\n",
       "      <td>1.711652e+09</td>\n",
       "      <td>1.773420e+18</td>\n",
       "      <td>67.0</td>\n",
       "      <td>es</td>\n",
       "      <td>08/02/2018</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>@nayibbukele Uff lancha nueva 😁</td>\n",
       "      <td>...</td>\n",
       "      <td>6211020.0</td>\n",
       "      <td>True</td>\n",
       "      <td>La embarcación que transportaba la droga ya es...</td>\n",
       "      <td>True</td>\n",
       "      <td>la embarcación que transportaba la droga ya es...</td>\n",
       "      <td>Government</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The tweet is neutral, simply stating the arriv...</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1968</td>\n",
       "      <td>6219</td>\n",
       "      <td>https://x.com/marquinan40/status/1761554116961...</td>\n",
       "      <td>1.708822e+09</td>\n",
       "      <td>1.761550e+18</td>\n",
       "      <td>99.0</td>\n",
       "      <td>es</td>\n",
       "      <td>09/08/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Vi11atoro @PNCSV Es lo menos q podemos hacer ...</td>\n",
       "      <td>...</td>\n",
       "      <td>66429.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Agradecemos a la población la confianza en rea...</td>\n",
       "      <td>False</td>\n",
       "      <td>agradecemos a la población la confianza en rea...</td>\n",
       "      <td>Government</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The tweet expresses gratitude and appreciation...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2293</td>\n",
       "      <td>7359</td>\n",
       "      <td>https://x.com/UnidadTps/status/176163107190775...</td>\n",
       "      <td>1.708841e+09</td>\n",
       "      <td>1.761630e+18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>es</td>\n",
       "      <td>22/01/2016</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>@MarceloLarin1 Todavia lloras porque no te die...</td>\n",
       "      <td>...</td>\n",
       "      <td>64221.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Hasta hoy la mujer más coherente que he visto ...</td>\n",
       "      <td>False</td>\n",
       "      <td>hasta hoy la mujer más coherente que he visto ...</td>\n",
       "      <td>Media</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>The tweet expresses criticism and disappointme...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2249</td>\n",
       "      <td>7197</td>\n",
       "      <td>https://x.com/lachele78/status/176466206779601...</td>\n",
       "      <td>1.709563e+09</td>\n",
       "      <td>1.764660e+18</td>\n",
       "      <td>7957.0</td>\n",
       "      <td>es</td>\n",
       "      <td>05/09/2020</td>\n",
       "      <td>El Salvador</td>\n",
       "      <td>@MarceloLarin1 @eybonluis Lonque el no entiend...</td>\n",
       "      <td>...</td>\n",
       "      <td>64221.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Nayib les quito el fodes a sus alcaldes, no ll...</td>\n",
       "      <td>False</td>\n",
       "      <td>nayib les quito el fodes a sus alcaldes no lle...</td>\n",
       "      <td>Media</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>The tweet expresses a negative sentiment as it...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2525</td>\n",
       "      <td>8144</td>\n",
       "      <td>https://x.com/BlancaEstela506/status/136669961...</td>\n",
       "      <td>1.614682e+09</td>\n",
       "      <td>1.366700e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>06/06/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@FranAlabi @nayibbukele Excelente!¡!  muy boni...</td>\n",
       "      <td>...</td>\n",
       "      <td>410702.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Áreas dignas para la población y el personal d...</td>\n",
       "      <td>True</td>\n",
       "      <td>áreas dignas para la población y el personal d...</td>\n",
       "      <td>Government</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The tweet expresses a positive sentiment by us...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0           532        1209   \n",
       "1          1968        6219   \n",
       "2          2293        7359   \n",
       "3          2249        7197   \n",
       "4          2525        8144   \n",
       "\n",
       "                                         comment_url  comment_createdAt  \\\n",
       "0  https://x.com/dany_u07/status/1773424640678838281       1.711652e+09   \n",
       "1  https://x.com/marquinan40/status/1761554116961...       1.708822e+09   \n",
       "2  https://x.com/UnidadTps/status/176163107190775...       1.708841e+09   \n",
       "3  https://x.com/lachele78/status/176466206779601...       1.709563e+09   \n",
       "4  https://x.com/BlancaEstela506/status/136669961...       1.614682e+09   \n",
       "\n",
       "     comment_id  comment_viewCount comment_lang comment_author_createdAt  \\\n",
       "0  1.773420e+18               67.0           es               08/02/2018   \n",
       "1  1.761550e+18               99.0           es               09/08/2022   \n",
       "2  1.761630e+18               13.0           es               22/01/2016   \n",
       "3  1.764660e+18             7957.0           es               05/09/2020   \n",
       "4  1.366700e+18                NaN           es               06/06/2019   \n",
       "\n",
       "  comment_location                                       comment_text  ...  \\\n",
       "0      Houston, TX                    @nayibbukele Uff lancha nueva 😁  ...   \n",
       "1              NaN  @Vi11atoro @PNCSV Es lo menos q podemos hacer ...  ...   \n",
       "2       Dallas, TX  @MarceloLarin1 Todavia lloras porque no te die...  ...   \n",
       "3      El Salvador  @MarceloLarin1 @eybonluis Lonque el no entiend...  ...   \n",
       "4              NaN  @FranAlabi @nayibbukele Excelente!¡!  muy boni...  ...   \n",
       "\n",
       "   post_followers post_verified  \\\n",
       "0       6211020.0          True   \n",
       "1         66429.0          True   \n",
       "2         64221.0          True   \n",
       "3         64221.0          True   \n",
       "4        410702.0          True   \n",
       "\n",
       "                                           post_text  \\\n",
       "0  La embarcación que transportaba la droga ya es...   \n",
       "1  Agradecemos a la población la confianza en rea...   \n",
       "2  Hasta hoy la mujer más coherente que he visto ...   \n",
       "3  Nayib les quito el fodes a sus alcaldes, no ll...   \n",
       "4  Áreas dignas para la población y el personal d...   \n",
       "\n",
       "   isActor_self__decalred__location__El_Salvador  \\\n",
       "0                                           True   \n",
       "1                                          False   \n",
       "2                                          False   \n",
       "3                                          False   \n",
       "4                                           True   \n",
       "\n",
       "                                 post_processed_text  actor_affiliation  \\\n",
       "0  la embarcación que transportaba la droga ya es...         Government   \n",
       "1  agradecemos a la población la confianza en rea...         Government   \n",
       "2  hasta hoy la mujer más coherente que he visto ...              Media   \n",
       "3  nayib les quito el fodes a sus alcaldes no lle...              Media   \n",
       "4  áreas dignas para la población y el personal d...         Government   \n",
       "\n",
       "   llama3_output                                      llama3_reason  \\\n",
       "0            0.0  The tweet is neutral, simply stating the arriv...   \n",
       "1            1.0  The tweet expresses gratitude and appreciation...   \n",
       "2           -1.0  The tweet expresses criticism and disappointme...   \n",
       "3           -1.0  The tweet expresses a negative sentiment as it...   \n",
       "4            1.0  The tweet expresses a positive sentiment by us...   \n",
       "\n",
       "   manual_labeling  open_ai_gpt4_base  \n",
       "0                0           Positive  \n",
       "1                1           Positive  \n",
       "2               -1           Negative  \n",
       "3               -1           Negative  \n",
       "4                1           Positive  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis completed. Labeled tweets saved to total_df_with_openai.csv.\n"
     ]
    }
   ],
   "source": [
    "# Save the final DataFrame to a new CSV file\n",
    "output_csv_file_path = 'total_df_with_openai.csv'\n",
    "df.to_csv(output_csv_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open_ai_gpt4_base\n",
       "Neutral     1059\n",
       "Negative     979\n",
       "Positive     959\n",
       "Pos            2\n",
       "Claro          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total labels generated\n",
    "\n",
    "df['open_ai_gpt4_base'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Replace \"Pos\" with \"Positive\" and \"Claro\" with \"Neutral\"\n",
    "df['open_ai_gpt4_base_cleaned'] = df['open_ai_gpt4_base'].replace({\n",
    "    'Pos': 'Positive',\n",
    "    'Claro': 'Neutral'\n",
    "})\n",
    "\n",
    "# Step 2: Map the sentiment values to the desired integers\n",
    "sentiment_mapping = {\n",
    "    'Negative': -1,\n",
    "    'Neutral': 0,\n",
    "    'Positive': 1\n",
    "}\n",
    "df['final_open_ai_gpt4_v1'] = df['open_ai_gpt4_base_cleaned'].map(sentiment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_url</th>\n",
       "      <th>comment_createdAt</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_viewCount</th>\n",
       "      <th>comment_lang</th>\n",
       "      <th>comment_author_createdAt</th>\n",
       "      <th>comment_location</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>...</th>\n",
       "      <th>post_text</th>\n",
       "      <th>isActor_self__decalred__location__El_Salvador</th>\n",
       "      <th>post_processed_text</th>\n",
       "      <th>actor_affiliation</th>\n",
       "      <th>llama3_output</th>\n",
       "      <th>llama3_reason</th>\n",
       "      <th>manual_labeling</th>\n",
       "      <th>open_ai_gpt4_base</th>\n",
       "      <th>open_ai_gpt4_base_cleaned</th>\n",
       "      <th>final_open_ai_gpt4_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>532</td>\n",
       "      <td>1209</td>\n",
       "      <td>https://x.com/dany_u07/status/1773424640678838281</td>\n",
       "      <td>1.711652e+09</td>\n",
       "      <td>1.773420e+18</td>\n",
       "      <td>67.0</td>\n",
       "      <td>es</td>\n",
       "      <td>08/02/2018</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>@nayibbukele Uff lancha nueva 😁</td>\n",
       "      <td>...</td>\n",
       "      <td>La embarcación que transportaba la droga ya es...</td>\n",
       "      <td>True</td>\n",
       "      <td>la embarcación que transportaba la droga ya es...</td>\n",
       "      <td>Government</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The tweet is neutral, simply stating the arriv...</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1968</td>\n",
       "      <td>6219</td>\n",
       "      <td>https://x.com/marquinan40/status/1761554116961...</td>\n",
       "      <td>1.708822e+09</td>\n",
       "      <td>1.761550e+18</td>\n",
       "      <td>99.0</td>\n",
       "      <td>es</td>\n",
       "      <td>09/08/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Vi11atoro @PNCSV Es lo menos q podemos hacer ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Agradecemos a la población la confianza en rea...</td>\n",
       "      <td>False</td>\n",
       "      <td>agradecemos a la población la confianza en rea...</td>\n",
       "      <td>Government</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The tweet expresses gratitude and appreciation...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2293</td>\n",
       "      <td>7359</td>\n",
       "      <td>https://x.com/UnidadTps/status/176163107190775...</td>\n",
       "      <td>1.708841e+09</td>\n",
       "      <td>1.761630e+18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>es</td>\n",
       "      <td>22/01/2016</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>@MarceloLarin1 Todavia lloras porque no te die...</td>\n",
       "      <td>...</td>\n",
       "      <td>Hasta hoy la mujer más coherente que he visto ...</td>\n",
       "      <td>False</td>\n",
       "      <td>hasta hoy la mujer más coherente que he visto ...</td>\n",
       "      <td>Media</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>The tweet expresses criticism and disappointme...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2249</td>\n",
       "      <td>7197</td>\n",
       "      <td>https://x.com/lachele78/status/176466206779601...</td>\n",
       "      <td>1.709563e+09</td>\n",
       "      <td>1.764660e+18</td>\n",
       "      <td>7957.0</td>\n",
       "      <td>es</td>\n",
       "      <td>05/09/2020</td>\n",
       "      <td>El Salvador</td>\n",
       "      <td>@MarceloLarin1 @eybonluis Lonque el no entiend...</td>\n",
       "      <td>...</td>\n",
       "      <td>Nayib les quito el fodes a sus alcaldes, no ll...</td>\n",
       "      <td>False</td>\n",
       "      <td>nayib les quito el fodes a sus alcaldes no lle...</td>\n",
       "      <td>Media</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>The tweet expresses a negative sentiment as it...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2525</td>\n",
       "      <td>8144</td>\n",
       "      <td>https://x.com/BlancaEstela506/status/136669961...</td>\n",
       "      <td>1.614682e+09</td>\n",
       "      <td>1.366700e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>06/06/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@FranAlabi @nayibbukele Excelente!¡!  muy boni...</td>\n",
       "      <td>...</td>\n",
       "      <td>Áreas dignas para la población y el personal d...</td>\n",
       "      <td>True</td>\n",
       "      <td>áreas dignas para la población y el personal d...</td>\n",
       "      <td>Government</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The tweet expresses a positive sentiment by us...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0           532        1209   \n",
       "1          1968        6219   \n",
       "2          2293        7359   \n",
       "3          2249        7197   \n",
       "4          2525        8144   \n",
       "\n",
       "                                         comment_url  comment_createdAt  \\\n",
       "0  https://x.com/dany_u07/status/1773424640678838281       1.711652e+09   \n",
       "1  https://x.com/marquinan40/status/1761554116961...       1.708822e+09   \n",
       "2  https://x.com/UnidadTps/status/176163107190775...       1.708841e+09   \n",
       "3  https://x.com/lachele78/status/176466206779601...       1.709563e+09   \n",
       "4  https://x.com/BlancaEstela506/status/136669961...       1.614682e+09   \n",
       "\n",
       "     comment_id  comment_viewCount comment_lang comment_author_createdAt  \\\n",
       "0  1.773420e+18               67.0           es               08/02/2018   \n",
       "1  1.761550e+18               99.0           es               09/08/2022   \n",
       "2  1.761630e+18               13.0           es               22/01/2016   \n",
       "3  1.764660e+18             7957.0           es               05/09/2020   \n",
       "4  1.366700e+18                NaN           es               06/06/2019   \n",
       "\n",
       "  comment_location                                       comment_text  ...  \\\n",
       "0      Houston, TX                    @nayibbukele Uff lancha nueva 😁  ...   \n",
       "1              NaN  @Vi11atoro @PNCSV Es lo menos q podemos hacer ...  ...   \n",
       "2       Dallas, TX  @MarceloLarin1 Todavia lloras porque no te die...  ...   \n",
       "3      El Salvador  @MarceloLarin1 @eybonluis Lonque el no entiend...  ...   \n",
       "4              NaN  @FranAlabi @nayibbukele Excelente!¡!  muy boni...  ...   \n",
       "\n",
       "                                           post_text  \\\n",
       "0  La embarcación que transportaba la droga ya es...   \n",
       "1  Agradecemos a la población la confianza en rea...   \n",
       "2  Hasta hoy la mujer más coherente que he visto ...   \n",
       "3  Nayib les quito el fodes a sus alcaldes, no ll...   \n",
       "4  Áreas dignas para la población y el personal d...   \n",
       "\n",
       "  isActor_self__decalred__location__El_Salvador  \\\n",
       "0                                          True   \n",
       "1                                         False   \n",
       "2                                         False   \n",
       "3                                         False   \n",
       "4                                          True   \n",
       "\n",
       "                                 post_processed_text  actor_affiliation  \\\n",
       "0  la embarcación que transportaba la droga ya es...         Government   \n",
       "1  agradecemos a la población la confianza en rea...         Government   \n",
       "2  hasta hoy la mujer más coherente que he visto ...              Media   \n",
       "3  nayib les quito el fodes a sus alcaldes no lle...              Media   \n",
       "4  áreas dignas para la población y el personal d...         Government   \n",
       "\n",
       "   llama3_output                                      llama3_reason  \\\n",
       "0            0.0  The tweet is neutral, simply stating the arriv...   \n",
       "1            1.0  The tweet expresses gratitude and appreciation...   \n",
       "2           -1.0  The tweet expresses criticism and disappointme...   \n",
       "3           -1.0  The tweet expresses a negative sentiment as it...   \n",
       "4            1.0  The tweet expresses a positive sentiment by us...   \n",
       "\n",
       "   manual_labeling  open_ai_gpt4_base  open_ai_gpt4_base_cleaned  \\\n",
       "0                0           Positive                   Positive   \n",
       "1                1           Positive                   Positive   \n",
       "2               -1           Negative                   Negative   \n",
       "3               -1           Negative                   Negative   \n",
       "4                1           Positive                   Positive   \n",
       "\n",
       "   final_open_ai_gpt4_v1  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                     -1  \n",
       "3                     -1  \n",
       "4                      1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.03%\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Calculate accuracy\n",
    "accuracy = (df['final_open_ai_gpt4_v1'] == df['manual_labeling']).mean()\n",
    "\n",
    "# Display the accuracy\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 79.03%\n",
      "Accuracy for -1: 72.61%\n",
      "Accuracy for 0: 75.87%\n",
      "Accuracy for 1: 91.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DhalS\\AppData\\Local\\Temp\\ipykernel_11008\\1340792081.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  class_accuracy = df.groupby('manual_labeling').apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with columns 'final_open_ai_gpt4_v1' and 'manual_labeling'\n",
    "\n",
    "# Step 1: Calculate overall accuracy\n",
    "overall_accuracy = (df['final_open_ai_gpt4_v1'] == df['manual_labeling']).mean()\n",
    "\n",
    "# Step 2: Calculate accuracy by each class\n",
    "class_accuracy = df.groupby('manual_labeling').apply(\n",
    "    lambda x: (x['final_open_ai_gpt4_v1'] == x['manual_labeling']).mean()\n",
    ").to_dict()\n",
    "\n",
    "# Step 3: Display the overall accuracy\n",
    "print(f'Overall Accuracy: {overall_accuracy * 100:.2f}%')\n",
    "\n",
    "# Step 4: Display accuracy by class\n",
    "for label, accuracy in class_accuracy.items():\n",
    "    print(f'Accuracy for {label}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('total_df_with_openai.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring base with emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Ensure the OpenAI API key is set\n",
    "\n",
    "# Define the function to get the sentiment response using zero-shot\n",
    "def get_response(example):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a sentiment analysis system. Analyze the sentiment of the politician tweets or tweet replies written in salvadorian spanish and return one word: Positive, Negative, or Neutral.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{example}\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "example_review = \"El servicio fue bueno pero la comida estaba insípida y fría.\"\n",
    "print(get_response(example_review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-LtJL7***************************************Y0Bd. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a new column for sentiment labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen_ai_gpt4_base_emoji\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomment_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[87], line 7\u001b[0m, in \u001b[0;36mget_response\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_response\u001b[39m(example):\n\u001b[1;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a sentiment analysis system. Analyze the sentiment of the politician tweets or tweet replies written in salvadorian spanish and return one word: Positive, Negative, or Neutral.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexample\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\resources\\chat\\completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:1261\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1249\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1256\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1257\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1258\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1259\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1260\u001b[0m     )\n\u001b[1;32m-> 1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1049\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-LtJL7***************************************Y0Bd. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a new column for sentiment labels\n",
    "df['open_ai_gpt4_base_emoji'] = df['comment_text'].apply(get_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring with Few Shots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import openai\n",
    "\n",
    "# Ensure the OpenAI API key is set\n",
    "\n",
    "# Define the function to get the sentiment response using few-shot examples\n",
    "def get_response_with_few_shot(example):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            You are sentiment analysis system and your job to  analyse a sentiment of a salvadorian spanish tweet or tweet reply and classify each tweet into only one of three categories based on its sentiment: Positive, Neutral, or Negative using a\n",
    "            local perspective from El Salvador political scene.\n",
    "\n",
    "            Guidelines:\n",
    "            Positive: The tweet expresses a positive sentiment, such as happiness, praise, or admiration.\n",
    "            Neutral: The tweet is neutral. It may present facts, ask questions, or be generally balanced in tone or a statement or just mention a fact or a name.\n",
    "            Negative: The tweet expresses a negative sentiment, such as criticism, disappointment, or disapproval.\n",
    "\n",
    "            Examples for Reference:\n",
    "\n",
    "            Positive:\n",
    "            . Tweet: \"Dios lo bendiga por ser un gran ser humano.\"\n",
    "            . Tweet: \"Me encanta la humanidad de nuestro astronauta, un hombre con gran corazón.\"\n",
    "            . Tweet: \"Dos grandes hombres haciendo historia. Gracias por todo.\"\n",
    "\n",
    "            Neutral:\n",
    "            . Tweet: \"Tweet Maria Alicia Alas Moreno.\"\n",
    "            . Tweet: \"Tweet Nuestros obstaculos son mentales.\"\n",
    "            . Tweet: \"¿Qué opinan sobre las últimas noticias del presidente?\"\n",
    "\n",
    "            Negative:\n",
    "            . Tweet: \"No estoy de acuerdo con las políticas actuales.\"\n",
    "            . Tweet: \"Es una vergüenza que esto esté sucediendo en nuestro país.\"\n",
    "            . Tweet: \"Las decisiones del presidente están dañando la economía.\"\n",
    "            \"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\". Tweet: \\\"{example}\\\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0,  # More deterministic\n",
    "        max_tokens=1,  # Limit to one token\n",
    "        top_p=0.9,  # Consider top tokens up to cumulative probability 0.9\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "example_review = \"El servicio fue bueno pero la comida estaba insípida y fría.\"\n",
    "generated_token = get_response_with_few_shot(example_review)\n",
    "print(f\"Generated Token: {generated_token}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['open_ai_gpt4_fewshot'] = df['comment_processed_text'].apply(get_response_with_few_shot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['open_ai_gpt4_fewshot'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Ensure the OpenAI API key is set\n",
    "\n",
    "# Define the function to get the sentiment response using few-shot\n",
    "def get_response_with_few_shot(example):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a sentiment analysis system. Analyze the sentiment of Salvadorian Spanish tweets posted by politicials or its spanish tweet replies by public and return one word: Positive, Negative, or Neutral.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"El servicio fue excelente, me encantó todo. - Positive\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Todo estuvo perfecto, muy recomendable. - Positive\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"ese es ramflero mayor el que lleva la palabra. - Negative\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"a mi me pusieron la segunda dosis el sábado y la verdad que esa si te da un dolor de huesos como desubicacion asi como cuando te quiere dar una fiebre dolor en el brazo y fatiga pero ya ayer como si nada me paso es asi creo q todos los pacientes pero todos somos diferentes. - Negative\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"La comida estuvo bien, nada especial. - Neutral\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"El lugar está limpio, pero el ambiente es regular. - Neutral\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{example}\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Example usage\n",
    "example_review = \"El servicio fue bueno pero la comida estaba insípida y fría.\"\n",
    "print(get_response(example_review))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
