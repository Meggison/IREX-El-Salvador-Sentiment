{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8817732,"sourceType":"datasetVersion","datasetId":5304568}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport pandas as pd\nimport torch\nfrom datetime import datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\nfrom transformers import TrainingArguments, Trainer, DataCollatorWithPadding\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, EarlyStoppingCallback\n\nfrom transformers import (\n    AutoTokenizer,\n    DataCollatorWithPadding,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    pipeline,\n)\n\n\n\n\n","metadata":{"id":"R-BV5UBnjMca","executionInfo":{"status":"ok","timestamp":1719660134707,"user_tz":-240,"elapsed":710,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:27:02.677041Z","iopub.execute_input":"2024-06-29T12:27:02.677956Z","iopub.status.idle":"2024-06-29T12:27:02.684850Z","shell.execute_reply.started":"2024-06-29T12:27:02.677921Z","shell.execute_reply":"2024-06-29T12:27:02.683830Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"!pip install mlflow dagshub","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bud8N_oZjhrA","executionInfo":{"status":"ok","timestamp":1719659877292,"user_tz":-240,"elapsed":27050,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"outputId":"63d169b3-93d4-4a32-b844-8482c94bcc41","execution":{"iopub.status.busy":"2024-06-29T11:48:11.747465Z","iopub.execute_input":"2024-06-29T11:48:11.748316Z","iopub.status.idle":"2024-06-29T11:48:42.424714Z","shell.execute_reply.started":"2024-06-29T11:48:11.748282Z","shell.execute_reply":"2024-06-29T11:48:42.423572Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting mlflow\n  Downloading mlflow-2.14.1-py3-none-any.whl.metadata (29 kB)\nCollecting dagshub\n  Downloading dagshub-0.3.28-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.0.3)\nRequirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.13.1)\nCollecting cachetools<6,>=5.0.0 (from mlflow)\n  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (7.0.0)\nRequirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.41)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.11.0)\nRequirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.5.2)\nRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.26.4)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\nRequirement already satisfied: packaging<25 in /opt/conda/lib/python3.10/site-packages (from mlflow) (21.3)\nRequirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.20.3)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (14.0.2)\nRequirement already satisfied: pytz<2025 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2023.3.post1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.0.1)\nCollecting querystring-parser<2 (from mlflow)\n  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\nRequirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.32.3)\nRequirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.11.4)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.0.25)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4.4)\nRequirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.2)\nCollecting gunicorn<23 (from mlflow)\n  Downloading gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting fusepy>=3 (from dagshub)\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from dagshub) (1.4.4)\nCollecting httpx~=0.23.0 (from dagshub)\n  Downloading httpx-0.23.3-py3-none-any.whl.metadata (7.1 kB)\nCollecting rich~=13.1.0 (from dagshub)\n  Downloading rich-13.1.0-py3-none-any.whl.metadata (18 kB)\nCollecting dacite~=1.6.0 (from dagshub)\n  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: tenacity~=8.2.2 in /opt/conda/lib/python3.10/site-packages (from dagshub) (8.2.3)\nCollecting gql[requests] (from dagshub)\n  Downloading gql-3.5.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from dagshub) (0.6.6)\nCollecting treelib~=1.6.4 (from dagshub)\n  Downloading treelib-1.6.4-py3-none-any.whl.metadata (1.4 kB)\nCollecting pathvalidate~=3.0.0 (from dagshub)\n  Downloading pathvalidate-3.0.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from dagshub) (2.9.0.post0)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from dagshub) (1.26.100)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.9.0)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.18)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (1.8.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nCollecting aniso8601<10,>=8 (from graphene<4->mlflow)\n  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx~=0.23.0->dagshub) (2024.2.2)\nCollecting httpcore<0.17.0,>=0.15.0 (from httpx~=0.23.0->dagshub)\n  Downloading httpcore-0.16.3-py3-none-any.whl.metadata (16 kB)\nCollecting rfc3986<2,>=1.3 (from rfc3986[idna2008]<2,>=1.3->httpx~=0.23.0->dagshub)\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx~=0.23.0->dagshub) (1.3.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.1.1)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow) (0.43b0)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil->dagshub) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.6)\nCollecting commonmark<0.10.0,>=0.9.0 (from rich~=13.1.0->dagshub)\n  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from rich~=13.1.0->dagshub) (2.17.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->dagshub)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->dagshub) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->dagshub) (0.6.2)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->dagshub) (3.21.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->dagshub) (0.9.0)\nRequirement already satisfied: yarl<2.0,>=1.6 in /opt/conda/lib/python3.10/site-packages (from gql[requests]->dagshub) (1.9.3)\nRequirement already satisfied: backoff<3.0,>=1.11.1 in /opt/conda/lib/python3.10/site-packages (from gql[requests]->dagshub) (2.2.1)\nRequirement already satisfied: anyio<5,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gql[requests]->dagshub) (4.2.0)\nCollecting requests-toolbelt<2,>=1.0.0 (from gql[requests]->dagshub)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.0->gql[requests]->dagshub) (1.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow) (1.14.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx~=0.23.0->dagshub) (0.14.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\nRequirement already satisfied: multidict>=4.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.0.4)\nDownloading mlflow-2.14.1-py3-none-any.whl (25.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dagshub-0.3.28-py3-none-any.whl (233 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.7/233.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\nDownloading dacite-1.6.0-py3-none-any.whl (12 kB)\nDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx-0.23.3-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathvalidate-3.0.0-py3-none-any.whl (21 kB)\nDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nDownloading rich-13.1.0-py3-none-any.whl (238 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading treelib-1.6.4-py3-none-any.whl (18 kB)\nDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nDownloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fusepy\n  Building wheel for fusepy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10487 sha256=4015a2dc06934ba3144bd7fcaa793db19667000ef11c55575314262348a948cb\n  Stored in directory: /root/.cache/pip/wheels/c0/18/f6/f0d6be9d0435e2677ce5cc758e91da50053dce456a346f08c5\nSuccessfully built fusepy\nInstalling collected packages: rfc3986, fusepy, commonmark, aniso8601, treelib, rich, querystring-parser, pathvalidate, graphql-core, dacite, cachetools, requests-toolbelt, httpcore, gunicorn, graphql-relay, gql, botocore, httpx, graphene, mlflow, dagshub\n  Attempting uninstall: rich\n    Found existing installation: rich 13.7.0\n    Uninstalling rich-13.7.0:\n      Successfully uninstalled rich-13.7.0\n  Attempting uninstall: dacite\n    Found existing installation: dacite 1.8.1\n    Uninstalling dacite-1.8.1:\n      Successfully uninstalled dacite-1.8.1\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 4.2.4\n    Uninstalling cachetools-4.2.4:\n      Successfully uninstalled cachetools-4.2.4\n  Attempting uninstall: requests-toolbelt\n    Found existing installation: requests-toolbelt 0.10.1\n    Uninstalling requests-toolbelt-0.10.1:\n      Successfully uninstalled requests-toolbelt-0.10.1\n  Attempting uninstall: httpcore\n    Found existing installation: httpcore 1.0.5\n    Uninstalling httpcore-1.0.5:\n      Successfully uninstalled httpcore-1.0.5\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.106\n    Uninstalling botocore-1.34.106:\n      Successfully uninstalled botocore-1.34.106\n  Attempting uninstall: httpx\n    Found existing installation: httpx 0.27.0\n    Uninstalling httpx-0.27.0:\n      Successfully uninstalled httpx-0.27.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\naiobotocore 2.13.0 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\naiobotocore 2.13.0 requires botocore<1.34.107,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\njupyterlab 4.2.1 requires httpx>=0.25.0, but you have httpx 0.23.3 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires dacite>=1.8, but you have dacite 1.6.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aniso8601-9.0.1 botocore-1.29.165 cachetools-5.3.2 commonmark-0.9.1 dacite-1.6.0 dagshub-0.3.28 fusepy-3.0.1 gql-3.5.0 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-22.0.0 httpcore-0.16.3 httpx-0.23.3 mlflow-2.14.1 pathvalidate-3.0.0 querystring-parser-1.2.4 requests-toolbelt-1.0.0 rfc3986-1.5.0 rich-13.1.0 treelib-1.6.4\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"SNsgLApGjbR9","executionInfo":{"status":"ok","timestamp":1719659879225,"user_tz":-240,"elapsed":1939,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"outputId":"c41da4f2-1d98-4144-891b-94c6e5830840","execution":{"iopub.status.busy":"2024-06-29T11:50:10.086866Z","iopub.execute_input":"2024-06-29T11:50:10.087751Z","iopub.status.idle":"2024-06-29T11:50:10.328652Z","shell.execute_reply.started":"2024-06-29T11:50:10.087718Z","shell.execute_reply":"2024-06-29T11:50:10.327621Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024/06/29 11:50:10 ERROR : Daemon timed out. Failed to terminate daemon pid 268: os: process already finished\n2024/06/29 11:50:10 Fatal error: daemon exited with error code 1\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"Sb7DAQXTjeCl","executionInfo":{"status":"ok","timestamp":1719659879226,"user_tz":-240,"elapsed":8,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\ndf_train = pd.read_csv(r'/kaggle/input/sample-3000/train_df_2100_manual_final.csv')\ndf_val = pd.read_csv(r'/kaggle/input/sample-3000/validation_df_450_manual_final.csv')\ndf_test = pd.read_csv(r'/kaggle/input/sample-3000/test_df_450_manual_final.csv')\n\n\n\ntotal_df = pd.concat([df_train, df_val, df_test], axis=0)\ntotal_df.shape\n\ndf_train.rename(columns={'manual labeling': 'manual_labeling'}, inplace=True)\ndf_val.rename(columns={'manual labeling': 'manual_labeling'}, inplace=True)\ndf_test.rename(columns={'manual labeling': 'manual_labeling'}, inplace=True)\ntotal_df.rename(columns={'manual labeling': 'manual_labeling'}, inplace=True)\n\n\ndf_train['manual_labeling_new'] = df_train['manual_labeling'].replace({-1: 0, 0: 1, 1: 2})\ndf_test['manual_labeling_new'] = df_test['manual_labeling'].replace({-1: 0, 0: 1, 1: 2})\ndf_val['manual_labeling_new'] = df_val['manual_labeling'].replace({-1: 0, 0: 1, 1: 2})\n\ntotal_df['manual_labeling_new'] = total_df['manual_labeling'].replace({-1: 0, 0: 1, 1: 2})\n","metadata":{"id":"BNgOIZDBjMcc","executionInfo":{"status":"ok","timestamp":1719660517396,"user_tz":-240,"elapsed":951,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:25:17.008762Z","iopub.execute_input":"2024-06-29T12:25:17.009152Z","iopub.status.idle":"2024-06-29T12:25:17.139586Z","shell.execute_reply.started":"2024-06-29T12:25:17.009126Z","shell.execute_reply":"2024-06-29T12:25:17.138568Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\n\ntokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")","metadata":{"id":"e0zpm5YajMcc","executionInfo":{"status":"ok","timestamp":1719660843764,"user_tz":-240,"elapsed":344,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:25:20.121129Z","iopub.execute_input":"2024-06-29T12:25:20.121926Z","iopub.status.idle":"2024-06-29T12:25:20.279439Z","shell.execute_reply.started":"2024-06-29T12:25:20.121893Z","shell.execute_reply":"2024-06-29T12:25:20.278423Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class SentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',  # Padding\n            truncation=True,       # Truncation\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n        return {\n            'text': text,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)  # Ensure labels are tensors of type long\n        }\n","metadata":{"id":"TDQp8GdpjMcc","executionInfo":{"status":"ok","timestamp":1719660869737,"user_tz":-240,"elapsed":446,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:25:23.071349Z","iopub.execute_input":"2024-06-29T12:25:23.071718Z","iopub.status.idle":"2024-06-29T12:25:23.079439Z","shell.execute_reply.started":"2024-06-29T12:25:23.071691Z","shell.execute_reply":"2024-06-29T12:25:23.078502Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Extract texts and labels\ntrain_texts = df_train['comment_processed_text'].tolist()\ntrain_labels = df_train['manual_labeling_new'].tolist()\nval_texts = df_val['comment_processed_text'].tolist()\nval_labels = df_val['manual_labeling_new'].tolist()\ntest_texts = df_test['comment_processed_text'].tolist()\ntest_labels = df_test['manual_labeling_new'].tolist()","metadata":{"id":"bxS6cQqbjMcd","executionInfo":{"status":"ok","timestamp":1719660871827,"user_tz":-240,"elapsed":368,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T11:52:17.853033Z","iopub.execute_input":"2024-06-29T11:52:17.853388Z","iopub.status.idle":"2024-06-29T11:52:17.859970Z","shell.execute_reply.started":"2024-06-29T11:52:17.853354Z","shell.execute_reply":"2024-06-29T11:52:17.858837Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\n\n# Create train, validation, and test datasets\ntrain_dataset = SentimentDataset(train_texts, train_labels, tokenizer, MAX_LEN)\nval_dataset = SentimentDataset(val_texts, val_labels, tokenizer, MAX_LEN)\ntest_dataset = SentimentDataset(test_texts, test_labels, tokenizer, MAX_LEN)","metadata":{"id":"4XJ7_KhqjMcd","executionInfo":{"status":"ok","timestamp":1719660873476,"user_tz":-240,"elapsed":458,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:27:18.307900Z","iopub.execute_input":"2024-06-29T12:27:18.308269Z","iopub.status.idle":"2024-06-29T12:27:18.313405Z","shell.execute_reply.started":"2024-06-29T12:27:18.308239Z","shell.execute_reply":"2024-06-29T12:27:18.312391Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qTwvZT0vAVD","executionInfo":{"status":"ok","timestamp":1719660874467,"user_tz":-240,"elapsed":12,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"outputId":"593f4a29-3669-45cb-c1c6-e20271662b72","execution":{"iopub.status.busy":"2024-06-29T12:27:21.852109Z","iopub.execute_input":"2024-06-29T12:27:21.852464Z","iopub.status.idle":"2024-06-29T12:27:21.869215Z","shell.execute_reply.started":"2024-06-29T12:27:21.852434Z","shell.execute_reply":"2024-06-29T12:27:21.868333Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"{'text': 'uff lancha nueva',\n 'input_ids': tensor([    4, 16397, 30977, 27666,  2035,     5,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'labels': tensor(1)}"},"metadata":{}}]},{"cell_type":"code","source":"import os\n# Ensure the output directory exists\noutput_dir = './results_beto'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# Ensure the logging directory exists\nlogging_dir = './logs'\nif not os.path.exists(logging_dir):\n    os.makedirs(logging_dir)","metadata":{"id":"aYbCOGrLjMcd","executionInfo":{"status":"ok","timestamp":1719660877358,"user_tz":-240,"elapsed":3,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T11:52:37.712066Z","iopub.execute_input":"2024-06-29T11:52:37.712857Z","iopub.status.idle":"2024-06-29T11:52:37.718188Z","shell.execute_reply.started":"2024-06-29T11:52:37.712822Z","shell.execute_reply":"2024-06-29T11:52:37.717167Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\nmodel = BertForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\", num_labels=3)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVP9kJ3sjMcd","executionInfo":{"status":"ok","timestamp":1719660880047,"user_tz":-240,"elapsed":1326,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"outputId":"4cb6007e-22fd-4dc1-ec5e-4dee43de0418","execution":{"iopub.status.busy":"2024-06-29T12:27:27.901191Z","iopub.execute_input":"2024-06-29T12:27:27.901648Z","iopub.status.idle":"2024-06-29T12:27:28.426676Z","shell.execute_reply.started":"2024-06-29T12:27:27.901613Z","shell.execute_reply":"2024-06-29T12:27:28.425704Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install accelerate -U","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwjixNHjlBEC","executionInfo":{"status":"ok","timestamp":1719659907085,"user_tz":-240,"elapsed":21337,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"outputId":"d19c488e-0a52-4f89-aca9-7e906a57ab25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip show accelerate\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHfd43nrrjTh","executionInfo":{"status":"ok","timestamp":1719659919918,"user_tz":-240,"elapsed":12859,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"outputId":"8205b537-36f6-48dc-d5b8-b214a68bd0cb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pip install transformers[torch]","metadata":{"id":"lq1i7e7urS15","executionInfo":{"status":"ok","timestamp":1719659919919,"user_tz":-240,"elapsed":10,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define custom metrics function\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T11:53:17.176857Z","iopub.execute_input":"2024-06-29T11:53:17.177686Z","iopub.status.idle":"2024-06-29T11:53:17.183153Z","shell.execute_reply.started":"2024-06-29T11:53:17.177647Z","shell.execute_reply":"2024-06-29T11:53:17.182063Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\n\n# Training Arguments\ntraining_args = TrainingArguments(\n    output_dir=output_dir,  # Use the output directory variable\n    num_train_epochs=20,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir=logging_dir,\n    report_to=[],\n)","metadata":{"id":"iKLlUkJBjMcd","executionInfo":{"status":"ok","timestamp":1719660888283,"user_tz":-240,"elapsed":375,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:02:12.869396Z","iopub.execute_input":"2024-06-29T12:02:12.869850Z","iopub.status.idle":"2024-06-29T12:02:12.901904Z","shell.execute_reply.started":"2024-06-29T12:02:12.869802Z","shell.execute_reply":"2024-06-29T12:02:12.901144Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Collator\ndata_collator = DataCollatorWithPadding(tokenizer)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,  # Add custom metrics\n    data_collator=data_collator       # Add data collator\n)","metadata":{"id":"-65TYbVkjMce","executionInfo":{"status":"ok","timestamp":1719660889668,"user_tz":-240,"elapsed":2,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:02:18.440077Z","iopub.execute_input":"2024-06-29T12:02:18.440712Z","iopub.status.idle":"2024-06-29T12:02:18.454400Z","shell.execute_reply.started":"2024-06-29T12:02:18.440683Z","shell.execute_reply":"2024-06-29T12:02:18.453533Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Training Arguments\ntraining_args = TrainingArguments(\n    output_dir=output_dir,  # Use the output directory variable\n    num_train_epochs=10,  # Increase number of epochs\n    per_device_train_batch_size=16,  # Adjust batch size\n    per_device_eval_batch_size=16,\n    learning_rate=2e-5,  # Adjust learning rate\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir=logging_dir,\n    eval_strategy=\"epoch\",  # Evaluate at each epoch\n    save_strategy=\"epoch\",  # Save at each epoch\n    save_total_limit=3,  # Only keep the last 3 checkpoints\n    load_best_model_at_end=True,  # Load the best model found during training at the end\n    metric_for_best_model=\"accuracy\",  # Use accuracy to determine the best model\n    greater_is_better=True,\n    report_to=[],  # Disable all integrations\n)","metadata":{"id":"QW9ilJv_jMce","executionInfo":{"status":"ok","timestamp":1719660892708,"user_tz":-240,"elapsed":559,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:27:36.850078Z","iopub.execute_input":"2024-06-29T12:27:36.850442Z","iopub.status.idle":"2024-06-29T12:27:36.882471Z","shell.execute_reply.started":"2024-06-29T12:27:36.850410Z","shell.execute_reply":"2024-06-29T12:27:36.881703Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Data Collator\ndata_collator = DataCollatorWithPadding(tokenizer)\n# Trainer with Early Stopping\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,  # Add custom metrics\n    data_collator=data_collator,       # Add data collator\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Add early stopping\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:27:39.918206Z","iopub.execute_input":"2024-06-29T12:27:39.918901Z","iopub.status.idle":"2024-06-29T12:27:40.068678Z","shell.execute_reply.started":"2024-06-29T12:27:39.918868Z","shell.execute_reply":"2024-06-29T12:27:40.067924Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"wDfmT9EMjMce","outputId":"0e27d687-2302-46e1-e5c4-611f7c499451","execution":{"iopub.status.busy":"2024-06-29T12:29:05.072131Z","iopub.execute_input":"2024-06-29T12:29:05.072818Z","iopub.status.idle":"2024-06-29T12:42:29.593266Z","shell.execute_reply.started":"2024-06-29T12:29:05.072784Z","shell.execute_reply":"2024-06-29T12:42:29.592341Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='462' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [462/660 13:22 < 05:45, 0.57 it/s, Epoch 7/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.019317</td>\n      <td>0.526667</td>\n      <td>0.475056</td>\n      <td>0.587979</td>\n      <td>0.526667</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.737039</td>\n      <td>0.680000</td>\n      <td>0.653878</td>\n      <td>0.711283</td>\n      <td>0.680000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.653039</td>\n      <td>0.722222</td>\n      <td>0.715969</td>\n      <td>0.718083</td>\n      <td>0.722222</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.635270</td>\n      <td>0.726667</td>\n      <td>0.729006</td>\n      <td>0.739699</td>\n      <td>0.726667</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.726107</td>\n      <td>0.713333</td>\n      <td>0.712583</td>\n      <td>0.718162</td>\n      <td>0.713333</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.725617</td>\n      <td>0.724444</td>\n      <td>0.724921</td>\n      <td>0.726731</td>\n      <td>0.724444</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.915165</td>\n      <td>0.708889</td>\n      <td>0.711573</td>\n      <td>0.716784</td>\n      <td>0.708889</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=462, training_loss=0.5870343493176745, metrics={'train_runtime': 803.7606, 'train_samples_per_second': 26.127, 'train_steps_per_second': 0.821, 'total_flos': 3867767240601600.0, 'train_loss': 0.5870343493176745, 'epoch': 7.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model on the validation set\nval_results = trainer.evaluate()\nprint(\"Validation Results:\", val_results)\n\n# Evaluate the model on the test set\ntest_results = trainer.evaluate(eval_dataset=test_dataset)\nprint(\"Test Results:\", test_results)\n\n","metadata":{"id":"SUB84F7RzWn5","execution":{"iopub.status.busy":"2024-06-29T12:43:55.325612Z","iopub.execute_input":"2024-06-29T12:43:55.326544Z","iopub.status.idle":"2024-06-29T12:44:11.376449Z","shell.execute_reply.started":"2024-06-29T12:43:55.326507Z","shell.execute_reply":"2024-06-29T12:44:11.375479Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Validation Results: {'eval_loss': 0.6352695226669312, 'eval_accuracy': 0.7266666666666667, 'eval_f1': 0.7290055924122579, 'eval_precision': 0.7396993251501143, 'eval_recall': 0.7266666666666667, 'eval_runtime': 7.9827, 'eval_samples_per_second': 56.372, 'eval_steps_per_second': 1.879, 'epoch': 7.0}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Test Results: {'eval_loss': 0.605351984500885, 'eval_accuracy': 0.7733333333333333, 'eval_f1': 0.7731599172459577, 'eval_precision': 0.7733569269335693, 'eval_recall': 0.7733333333333333, 'eval_runtime': 8.0612, 'eval_samples_per_second': 55.823, 'eval_steps_per_second': 1.861, 'epoch': 7.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"val_results","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:44:11.399090Z","iopub.execute_input":"2024-06-29T12:44:11.399690Z","iopub.status.idle":"2024-06-29T12:44:11.408385Z","shell.execute_reply.started":"2024-06-29T12:44:11.399658Z","shell.execute_reply":"2024-06-29T12:44:11.407554Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.6352695226669312,\n 'eval_accuracy': 0.7266666666666667,\n 'eval_f1': 0.7290055924122579,\n 'eval_precision': 0.7396993251501143,\n 'eval_recall': 0.7266666666666667,\n 'eval_runtime': 7.9827,\n 'eval_samples_per_second': 56.372,\n 'eval_steps_per_second': 1.879,\n 'epoch': 7.0}"},"metadata":{}}]},{"cell_type":"code","source":"test_results","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:44:17.499580Z","iopub.execute_input":"2024-06-29T12:44:17.500181Z","iopub.status.idle":"2024-06-29T12:44:17.506007Z","shell.execute_reply.started":"2024-06-29T12:44:17.500149Z","shell.execute_reply":"2024-06-29T12:44:17.505035Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.605351984500885,\n 'eval_accuracy': 0.7733333333333333,\n 'eval_f1': 0.7731599172459577,\n 'eval_precision': 0.7733569269335693,\n 'eval_recall': 0.7733333333333333,\n 'eval_runtime': 8.0612,\n 'eval_samples_per_second': 55.823,\n 'eval_steps_per_second': 1.861,\n 'epoch': 7.0}"},"metadata":{}}]},{"cell_type":"code","source":"# Generate and print the classification report for validation set\npreds_val = trainer.predict(val_dataset)\nlabels_val = preds_val.label_ids\npredictions_val = preds_val.predictions.argmax(-1)\nprint(\"\\nClassification Report (Validation):\")\nprint(classification_report(labels_val, predictions_val, target_names=['negative', 'neutral', 'positive']))\n\n# Generate and print the classification report for test set\npreds_test = trainer.predict(test_dataset)\nlabels_test = preds_test.label_ids\npredictions_test = preds_test.predictions.argmax(-1)\nprint(\"\\nClassification Report (Test):\")\nprint(classification_report(labels_test, predictions_test, target_names=['negative', 'neutral', 'positive']))","metadata":{"id":"xy30uCLjjMce","executionInfo":{"status":"aborted","timestamp":1719659589999,"user_tz":-240,"elapsed":12,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:44:21.928471Z","iopub.execute_input":"2024-06-29T12:44:21.929099Z","iopub.status.idle":"2024-06-29T12:44:38.494507Z","shell.execute_reply.started":"2024-06-29T12:44:21.929067Z","shell.execute_reply":"2024-06-29T12:44:38.493539Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"\nClassification Report (Validation):\n              precision    recall  f1-score   support\n\n    negative       0.81      0.67      0.74       181\n     neutral       0.59      0.70      0.64       138\n    positive       0.79      0.82      0.81       131\n\n    accuracy                           0.73       450\n   macro avg       0.73      0.73      0.73       450\nweighted avg       0.74      0.73      0.73       450\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nClassification Report (Test):\n              precision    recall  f1-score   support\n\n    negative       0.82      0.80      0.81       181\n     neutral       0.69      0.69      0.69       138\n    positive       0.80      0.83      0.81       131\n\n    accuracy                           0.77       450\n   macro avg       0.77      0.77      0.77       450\nweighted avg       0.77      0.77      0.77       450\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the paths where you want to save the model and tokenizer\nimport os\n\nmodel_save_path = './saved_model'\nif not os.path.exists(model_save_path):\n    os.makedirs(model_save_path)\n\ntokenizer_save_path = './saved_tokenizer'\nif not os.path.exists(tokenizer_save_path):\n    os.makedirs(tokenizer_save_path)\n\n    \n\n","metadata":{"id":"NNgZILTHjMce","executionInfo":{"status":"aborted","timestamp":1719659589999,"user_tz":-240,"elapsed":11,"user":{"displayName":"Sagar Dhal","userId":"16455285604145520351"}},"execution":{"iopub.status.busy":"2024-06-29T12:54:50.705576Z","iopub.execute_input":"2024-06-29T12:54:50.705979Z","iopub.status.idle":"2024-06-29T12:54:50.711731Z","shell.execute_reply.started":"2024-06-29T12:54:50.705949Z","shell.execute_reply":"2024-06-29T12:54:50.710746Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Save the model\nmodel.save_pretrained(model_save_path)\n\n# Save the tokenizer\ntokenizer.save_pretrained(tokenizer_save_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:23:46.713969Z","iopub.execute_input":"2024-06-29T12:23:46.714328Z","iopub.status.idle":"2024-06-29T12:23:47.584337Z","shell.execute_reply.started":"2024-06-29T12:23:46.714298Z","shell.execute_reply":"2024-06-29T12:23:47.583597Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"('./saved_tokenizer/tokenizer_config.json',\n './saved_tokenizer/special_tokens_map.json',\n './saved_tokenizer/vocab.txt',\n './saved_tokenizer/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"pip install datetime","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:21:31.345763Z","iopub.execute_input":"2024-06-29T12:21:31.346115Z","iopub.status.idle":"2024-06-29T12:21:44.896412Z","shell.execute_reply.started":"2024-06-29T12:21:31.346090Z","shell.execute_reply":"2024-06-29T12:21:44.895235Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting datetime\n  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\nCollecting zope.interface (from datetime)\n  Downloading zope.interface-6.4.post2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m766.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from datetime) (2023.3.post1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from zope.interface->datetime) (69.0.3)\nDownloading DateTime-5.5-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading zope.interface-6.4.post2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: zope.interface, datetime\nSuccessfully installed datetime-5.5 zope.interface-6.4.post2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model and tokenizer with a unique name\nimport datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nmodel_save_path = f'./saved_model_{timestamp}'\ntokenizer_save_path = f'./saved_tokenizer_{timestamp}'\n\nif not os.path.exists(model_save_path):\n    os.makedirs(model_save_path)\nif not os.path.exists(tokenizer_save_path):\n    os.makedirs(tokenizer_save_path)\n\n# Save the model\nmodel.save_pretrained(model_save_path)\n\n# Save the tokenizer\ntokenizer.save_pretrained(tokenizer_save_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:22:07.991914Z","iopub.execute_input":"2024-06-29T12:22:07.992612Z","iopub.status.idle":"2024-06-29T12:22:08.038886Z","shell.execute_reply.started":"2024-06-29T12:22:07.992570Z","shell.execute_reply":"2024-06-29T12:22:08.037769Z"},"trusted":true},"execution_count":38,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the model and tokenizer with a unique name\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m tokenizer_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_tokenizer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n","\u001b[0;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'now'"],"ename":"AttributeError","evalue":"module 'datetime' has no attribute 'now'","output_type":"error"}]}]}