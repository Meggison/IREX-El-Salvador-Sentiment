{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>collaborator_filtering</th>\n",
       "      <th>political actor</th>\n",
       "      <th>post_dataset</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post url</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>post_category</th>\n",
       "      <th>comment scraping status</th>\n",
       "      <th>comment dataset link</th>\n",
       "      <th>collaborator_scraping</th>\n",
       "      <th>Scraping Remarks</th>\n",
       "      <th>Scraped row count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>We're offering 5,000 free passports (equivalen...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1776733270186...</td>\n",
       "      <td>8134.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Replies_post_id_1</td>\n",
       "      <td>Dhruv Yadav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>No es el primero, y tampoco será el último.\\n\\...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1783714043573...</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Replies_1783714043573702940</td>\n",
       "      <td>Sagar</td>\n",
       "      <td>removed replies with replyis=false</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>Durante el medio siglo de guerra que vivió nue...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1775699870231...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Replies_1775699870231224819</td>\n",
       "      <td>Sagar</td>\n",
       "      <td>removed replies with replyis=false</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>En 2015, estando en la Alcaldía de San Salvado...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1787301391087...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Bukele_X_Replies_1787301391087587431.xlsx</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>Nuestra Marina Nacional incautó una lancha a 4...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1773039460256...</td>\n",
       "      <td>722.0</td>\n",
       "      <td>social</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Bukele_X_Replies_1773039460256477463.xlsx</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id collaborator_filtering political actor             post_dataset  \\\n",
       "0  1.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "1  2.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "2  3.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "3  4.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "4  5.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "\n",
       "                                           post_text  \\\n",
       "0  We're offering 5,000 free passports (equivalen...   \n",
       "1  No es el primero, y tampoco será el último.\\n\\...   \n",
       "2  Durante el medio siglo de guerra que vivió nue...   \n",
       "3  En 2015, estando en la Alcaldía de San Salvado...   \n",
       "4  Nuestra Marina Nacional incautó una lancha a 4...   \n",
       "\n",
       "                                            post url  reply_count  \\\n",
       "0  https://x.com/nayibbukele/status/1776733270186...       8134.0   \n",
       "1  https://x.com/nayibbukele/status/1783714043573...       1290.0   \n",
       "2  https://x.com/nayibbukele/status/1775699870231...       1000.0   \n",
       "3  https://x.com/nayibbukele/status/1787301391087...        870.0   \n",
       "4  https://x.com/nayibbukele/status/1773039460256...        722.0   \n",
       "\n",
       "  post_category comment scraping status  \\\n",
       "0      politics           Scraping Done   \n",
       "1      politics           Scraping Done   \n",
       "2      politics           Scraping Done   \n",
       "3      politics           Scraping Done   \n",
       "4        social           Scraping Done   \n",
       "\n",
       "                        comment dataset link collaborator_scraping  \\\n",
       "0                          Replies_post_id_1           Dhruv Yadav   \n",
       "1                Replies_1783714043573702940                 Sagar   \n",
       "2                Replies_1775699870231224819                 Sagar   \n",
       "3  Bukele_X_Replies_1787301391087587431.xlsx                Obinna   \n",
       "4  Bukele_X_Replies_1773039460256477463.xlsx                Obinna   \n",
       "\n",
       "                     Scraping Remarks  Scraped row count  \n",
       "0                                 NaN                NaN  \n",
       "1  removed replies with replyis=false               99.0  \n",
       "2  removed replies with replyis=false              101.0  \n",
       "3                                 NaN               39.0  \n",
       "4                                 NaN               50.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = '/Users/misanmeggison/Desktop/omdena_scraping/Data Collection Sheet - IREX_EL_SALVADOR - Selected Posts - Comment Scraping.csv'\n",
    "\n",
    "# Read second sheet of the excel file\n",
    "scraping_data = pd.read_csv(file_path)\n",
    "\n",
    "scraping_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>collaborator_filtering</th>\n",
       "      <th>political actor</th>\n",
       "      <th>post_dataset</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post url</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>post_category</th>\n",
       "      <th>comment scraping status</th>\n",
       "      <th>comment dataset link</th>\n",
       "      <th>collaborator_scraping</th>\n",
       "      <th>Scraping Remarks</th>\n",
       "      <th>Scraped row count</th>\n",
       "      <th>political_actor</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>We're offering 5,000 free passports (equivalen...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1776733270186...</td>\n",
       "      <td>8134.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Replies_post_id_1</td>\n",
       "      <td>Dhruv Yadav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nayibbukele</td>\n",
       "      <td>1776733270186545406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>No es el primero, y tampoco será el último.\\n\\...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1783714043573...</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Replies_1783714043573702940</td>\n",
       "      <td>Sagar</td>\n",
       "      <td>removed replies with replyis=false</td>\n",
       "      <td>99.0</td>\n",
       "      <td>nayibbukele</td>\n",
       "      <td>1783714043573702940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>Durante el medio siglo de guerra que vivió nue...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1775699870231...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Replies_1775699870231224819</td>\n",
       "      <td>Sagar</td>\n",
       "      <td>removed replies with replyis=false</td>\n",
       "      <td>101.0</td>\n",
       "      <td>nayibbukele</td>\n",
       "      <td>1775699870231224819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>En 2015, estando en la Alcaldía de San Salvado...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1787301391087...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>politics</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Bukele_X_Replies_1787301391087587431.xlsx</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>nayibbukele</td>\n",
       "      <td>1787301391087587431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>Bukele</td>\n",
       "      <td>Nayib Bukele's X Posts</td>\n",
       "      <td>Nuestra Marina Nacional incautó una lancha a 4...</td>\n",
       "      <td>https://x.com/nayibbukele/status/1773039460256...</td>\n",
       "      <td>722.0</td>\n",
       "      <td>social</td>\n",
       "      <td>Scraping Done</td>\n",
       "      <td>Bukele_X_Replies_1773039460256477463.xlsx</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>nayibbukele</td>\n",
       "      <td>1773039460256477463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id collaborator_filtering political actor             post_dataset  \\\n",
       "0  1.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "1  2.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "2  3.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "3  4.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "4  5.0                     AP           Bukele  Nayib Bukele's X Posts   \n",
       "\n",
       "                                           post_text  \\\n",
       "0  We're offering 5,000 free passports (equivalen...   \n",
       "1  No es el primero, y tampoco será el último.\\n\\...   \n",
       "2  Durante el medio siglo de guerra que vivió nue...   \n",
       "3  En 2015, estando en la Alcaldía de San Salvado...   \n",
       "4  Nuestra Marina Nacional incautó una lancha a 4...   \n",
       "\n",
       "                                            post url  reply_count  \\\n",
       "0  https://x.com/nayibbukele/status/1776733270186...       8134.0   \n",
       "1  https://x.com/nayibbukele/status/1783714043573...       1290.0   \n",
       "2  https://x.com/nayibbukele/status/1775699870231...       1000.0   \n",
       "3  https://x.com/nayibbukele/status/1787301391087...        870.0   \n",
       "4  https://x.com/nayibbukele/status/1773039460256...        722.0   \n",
       "\n",
       "  post_category comment scraping status  \\\n",
       "0      politics           Scraping Done   \n",
       "1      politics           Scraping Done   \n",
       "2      politics           Scraping Done   \n",
       "3      politics           Scraping Done   \n",
       "4        social           Scraping Done   \n",
       "\n",
       "                        comment dataset link collaborator_scraping  \\\n",
       "0                          Replies_post_id_1           Dhruv Yadav   \n",
       "1                Replies_1783714043573702940                 Sagar   \n",
       "2                Replies_1775699870231224819                 Sagar   \n",
       "3  Bukele_X_Replies_1787301391087587431.xlsx                Obinna   \n",
       "4  Bukele_X_Replies_1773039460256477463.xlsx                Obinna   \n",
       "\n",
       "                     Scraping Remarks  Scraped row count political_actor  \\\n",
       "0                                 NaN                NaN     nayibbukele   \n",
       "1  removed replies with replyis=false               99.0     nayibbukele   \n",
       "2  removed replies with replyis=false              101.0     nayibbukele   \n",
       "3                                 NaN               39.0     nayibbukele   \n",
       "4                                 NaN               50.0     nayibbukele   \n",
       "\n",
       "               post_id  \n",
       "0  1776733270186545406  \n",
       "1  1783714043573702940  \n",
       "2  1775699870231224819  \n",
       "3  1787301391087587431  \n",
       "4  1773039460256477463  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract political actor and post_id from post_url\n",
    "scraping_data['political_actor'] = scraping_data['post url'].str.extract(r'(?:x\\.com|twitter\\.com)/(\\w+)/status')\n",
    "scraping_data['post_id'] = scraping_data['post url'].str.extract(r'(?:x\\.com|twitter\\.com)/\\w+/status/(\\d+)')\n",
    "\n",
    "# Save the data\n",
    "scraping_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CarlosManciaSv': ['1759279446081839551'],\n",
       " 'ChristianDiffer': ['1302062819249197057',\n",
       "  '1230718665638629382',\n",
       "  '1263845340630986752',\n",
       "  '1479893801082802179',\n",
       "  '1184880306593107970',\n",
       "  '1265141803881320450',\n",
       "  '1298752115083485187',\n",
       "  '1179423903959179265',\n",
       "  '1279930054387130369',\n",
       "  '1230244851544985600',\n",
       "  '1460009018492170248'],\n",
       " 'FranAlabi': ['1699541231196410228',\n",
       "  '1660741726393212928',\n",
       "  '1660153154791456768',\n",
       "  '1391568130200190981',\n",
       "  '1377075242875650048',\n",
       "  '1366562547512573955',\n",
       "  '1362080410595958789',\n",
       "  '1299463579020730371',\n",
       "  '1297005925518245888',\n",
       "  '1296841357210857473',\n",
       "  '1289648537379041280',\n",
       "  '1287196168456417282',\n",
       "  '1285004325333409792',\n",
       "  '1276687900734902272',\n",
       "  '1274563361045438464'],\n",
       " 'MarceloLarin1': ['1759942551593746709',\n",
       "  '1759232096231407675',\n",
       "  '1781045162510061665',\n",
       "  '1764631323182821585',\n",
       "  '1761488482059403300',\n",
       "  '1777826121175748874',\n",
       "  '1761503340314116558',\n",
       "  '1760293688482173384',\n",
       "  '1762591914203693455',\n",
       "  '1769124519958987101',\n",
       "  '1777015697664540849',\n",
       "  '1766883671997399247',\n",
       "  '1774118316648599645',\n",
       "  '1773812404637548809',\n",
       "  '1777306574224081336',\n",
       "  '1780353315630379100',\n",
       "  '1781327015326392626',\n",
       "  '1774919380192870726',\n",
       "  '1769924171952234994',\n",
       "  '1764499656850260166',\n",
       "  '1774927390013272344'],\n",
       " 'MariaLuisaHayem': ['1270013941469626368',\n",
       "  '1317915762653302785',\n",
       "  '1262590426357391361',\n",
       "  '1266908776117960704',\n",
       "  '1270103548244746241',\n",
       "  '1256694196427264003',\n",
       "  '1266908778286518272',\n",
       "  '1270121333968572424',\n",
       "  '1270013943679942659',\n",
       "  '1573682267133706241',\n",
       "  '1434953238042849283',\n",
       "  '1268038746907250689'],\n",
       " 'NoticieroSLV': ['1785683289354715405',\n",
       "  '1785687050705924171',\n",
       "  '1783307438315258095',\n",
       "  '1783806980257366367'],\n",
       " 'PulsoCiudadanos': ['1751066997859782924',\n",
       "  '1782970937341624684',\n",
       "  '1740923091436613794',\n",
       "  '1765926079418572987',\n",
       "  '1760148904681640184'],\n",
       " 'Vi11atoro': ['1788720348776567255',\n",
       "  '1778618349162791374',\n",
       "  '1762477634531758188',\n",
       "  '1767373813526737223',\n",
       "  '1767614710155715049',\n",
       "  '1761495675777212428',\n",
       "  '1777333531716235689',\n",
       "  '1763075516829966767',\n",
       "  '1762285794952147099',\n",
       "  '1765932707098329105'],\n",
       " 'andresguzm': ['1777722104395313337',\n",
       "  '1727067358349414796',\n",
       "  '1743277817154916369',\n",
       "  '1760607082376519973',\n",
       "  '1769337928327614558',\n",
       "  '1682728543069896705',\n",
       "  '1743328759866851688',\n",
       "  '1599405529486409730'],\n",
       " 'easegura': ['1755993933346222579',\n",
       "  '1755298359005352291',\n",
       "  '1729693076954681485',\n",
       "  '1664508542294933504',\n",
       "  '1497703508744753152',\n",
       "  '1476746897196994567',\n",
       "  '1476746897196994567',\n",
       "  '1457459474596343808',\n",
       "  '1442281871983976451',\n",
       "  '1434017514221195266',\n",
       "  '1417991263928954880',\n",
       "  '1123660071903297536'],\n",
       " 'fulloa51': ['1770936553839145077',\n",
       "  '1785089834446356753',\n",
       "  '1785645992382996952',\n",
       "  '1764113365964653035',\n",
       "  '1788773644874744120',\n",
       "  '1763375373742395812',\n",
       "  '1775989419977167225'],\n",
       " 'nayibbukele': ['1776733270186545406',\n",
       "  '1783714043573702940',\n",
       "  '1775699870231224819',\n",
       "  '1787301391087587431',\n",
       "  '1773039460256477463',\n",
       "  '1773738164651241807',\n",
       "  '1773195373512708317',\n",
       "  '1788014378324754680',\n",
       "  '1785860243542417524',\n",
       "  '1777427641420636255',\n",
       "  '1773114767801995677'],\n",
       " 'suecallejas': ['1786430963947335686',\n",
       "  '1785059015241662849',\n",
       "  '1785061557413581164',\n",
       "  '1785029768347353163',\n",
       "  '1785029768347353163',\n",
       "  '1786161451335295068',\n",
       "  '1788666653514846531',\n",
       "  '1786191309767655900',\n",
       "  '1785125710568309081',\n",
       "  '1786560665257202069',\n",
       "  '1785857694357700867',\n",
       "  '1785124788811210985'],\n",
       " 'waraujo64': ['1782782951068979568',\n",
       "  '1782057167580741806',\n",
       "  '1782761311526391916',\n",
       "  '1780369690612670565',\n",
       "  '1779956955219448096',\n",
       "  '1785023580809376158'],\n",
       " 'ysuca91siete': ['1773469661520109990',\n",
       "  '1785704402168242639',\n",
       "  '1785082871352537458',\n",
       "  '1776988305906606587',\n",
       "  '1785711922479808742',\n",
       "  '1783879797468168553',\n",
       "  '1776701409460633813',\n",
       "  '1784237091460649170',\n",
       "  '1779898296737079312',\n",
       "  '1786046500583190702']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dict of political actors and their respective post_ids\n",
    "political_actor_dict = scraping_data.groupby('political_actor')['post_id'].apply(list).to_dict()\n",
    "\n",
    "# Save the dict to a file\n",
    "political_actor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarlosManciaSv 1\n",
      "ChristianDiffer 11\n",
      "FranAlabi 15\n",
      "MarceloLarin1 21\n",
      "MariaLuisaHayem 12\n",
      "NoticieroSLV 4\n",
      "PulsoCiudadanos 5\n",
      "Vi11atoro 10\n",
      "andresguzm 8\n",
      "easegura 12\n",
      "fulloa51 7\n",
      "suecallejas 12\n",
      "waraujo64 6\n",
      "ysuca91siete 10\n"
     ]
    }
   ],
   "source": [
    "# excluse nayibbukele from the dict\n",
    "# del political_actor_dict['nayibbukele']  #  excluding nayibbukele because data is already available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Vi11atoro - Post ID: 1788720348776567255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['id'] = out_data['id'].astype(str)\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['Political Actor'] = political_actor\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['originalTweet'] = out_data['text'].iloc[0]\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data.drop(out_data.index[0], inplace=True, axis=0)\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['text'] = out_data['text'].apply(clean_text)\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['text'] = out_data['text'].map(lambda x: x if x != '' else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Vi11atoro - Post ID: 1788720348776567255 saved to /Users/misanmeggison/Desktop/omdena_scraping/Vi11atoro_1788720348776567255.xlsx\n",
      "Processing Vi11atoro - Post ID: 1778618349162791374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['id'] = out_data['id'].astype(str)\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['Political Actor'] = political_actor\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['originalTweet'] = out_data['text'].iloc[0]\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data.drop(out_data.index[0], inplace=True, axis=0)\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['text'] = out_data['text'].apply(clean_text)\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/3130736876.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['text'] = out_data['text'].map(lambda x: x if x != '' else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Vi11atoro - Post ID: 1778618349162791374 saved to /Users/misanmeggison/Desktop/omdena_scraping/Vi11atoro_1778618349162791374.xlsx\n",
      "Processing Vi11atoro - Post ID: 1762477634531758188\n"
     ]
    }
   ],
   "source": [
    "from apify_client import ApifyClient\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Initialize the ApifyClient with your API token\n",
    "client = ApifyClient(\"YOUR_APIFY_API_TOKEN\")\n",
    "\n",
    "# Function to clean individual text entries\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s,]', '', text)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Function to process tweet data\n",
    "def process_tweet_data(df, political_actor):\n",
    "    out_data = df[['id', 'url', 'text', 'likeCount', 'viewCount', 'conversationId', 'lang', 'createdAt', 'retweetCount', 'source', 'isRetweet', 'twitterUrl', 'replyCount', 'quoteCount', 'isQuote', 'isReply']]\n",
    "    out_data['id'] = out_data['id'].astype(str)\n",
    "    out_data['Political Actor'] = political_actor\n",
    "    if not out_data.empty:\n",
    "        out_data['originalTweet'] = out_data['text'].iloc[0]\n",
    "    out_data.drop(out_data.index[0], inplace=True, axis=0)\n",
    "    out_data['text'] = out_data['text'].apply(clean_text)\n",
    "    out_data['text'] = out_data['text'].map(lambda x: x if x != '' else None)\n",
    "    out_data = out_data.dropna(subset=['text'])\n",
    "    return out_data\n",
    "\n",
    "# Iterate through each political actor and their post IDs\n",
    "save_directory = '/Users/misanmeggison/Desktop/omdena_scraping/'\n",
    "\n",
    "for political_actor, post_ids in political_actor_dict.items():\n",
    "    for post_id in post_ids:\n",
    "        print(f\"Processing {political_actor} - Post ID: {post_id}\")\n",
    "\n",
    "        run_input = {\n",
    "            \"startUrls\": [\n",
    "                f\"https://x.com/{political_actor}/status/{post_id}/with_replies\",\n",
    "            ],\n",
    "            \"searchTerms\": [\n",
    "                \"web scraping\",\n",
    "                \"scraping from:apify\",\n",
    "            ],\n",
    "            \"twitterHandles\": [\n",
    "                political_actor,\n",
    "            ],\n",
    "            \"conversationIds\": [\n",
    "                post_id,\n",
    "            ],\n",
    "            \"maxItems\": 100,\n",
    "            \"sort\": \"Top\",\n",
    "            \"author\": \"apify\",\n",
    "        }\n",
    "\n",
    "        run = client.actor(\"61RPP7dywgiy0JPD0\").call(run_input=run_input, memory_mbytes=256)\n",
    "        results = []\n",
    "\n",
    "        for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "            results.append(item)\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "        if not df.empty:\n",
    "            processed_data = process_tweet_data(df, political_actor)\n",
    "            file_name = f\"{political_actor}_{post_id}.xlsx\"\n",
    "            file_path = os.path.join(save_directory, file_name)\n",
    "\n",
    "            with pd.ExcelWriter(file_path) as writer:\n",
    "                df.to_excel(writer, sheet_name='Original Data', index=False)\n",
    "                processed_data.to_excel(writer, sheet_name='Preprocessed Data', index=False)\n",
    "\n",
    "            print(f\"Data for {political_actor} - Post ID: {post_id} saved to {file_path}\")\n",
    "\n",
    "print(\"Data processing and saving complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<apify_client.client.ApifyClient object at 0x178a2fc10>\n"
     ]
    }
   ],
   "source": [
    "# from apify_client import ApifyClient\n",
    "\n",
    "# # Initialize the ApifyClient with your API token\n",
    "# client = ApifyClient(\"YOUR_APIFY_API_TOKEN\")\n",
    "\n",
    "# # Replace with appropriate values\n",
    "# political_actor = 'waraujo64'\n",
    "# post_id = '1782057167580741806'\n",
    "\n",
    "\n",
    "# print(client)\n",
    "# # Prepare the Actor input\n",
    "# run_input = {\n",
    "#     \"startUrls\": [\n",
    "#         f\"https://x.com/{political_actor}/status/{post_id}/with_replies\",\n",
    "#     ],\n",
    "#     \"searchTerms\": [\n",
    "#         \"web scraping\",\n",
    "#         \"scraping from:apify\",\n",
    "#     ],\n",
    "#     \"twitterHandles\": [\n",
    "#         political_actor,\n",
    "#     ],\n",
    "#     \"conversationIds\": [\n",
    "#         post_id,\n",
    "#     ],\n",
    "#     \"maxItems\": 100,\n",
    "#     \"sort\": \"Top\",\n",
    "#     \"tweetLanguage\": \"en\",\n",
    "#     \"author\": \"apify\",\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify a lower memory limit for the Actor run\n",
    "# run = client.actor(\"61RPP7dywgiy0JPD0\").call(run_input=run_input, memory_mbytes=256)\n",
    "\n",
    "# # Initialize list to store the results\n",
    "# results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'geiE4cwPRLT5rQ6W9', 'actId': '61RPP7dywgiy0JPD0', 'userId': 'bEHzYmHe2Ju3ToARm', 'startedAt': datetime.datetime(2024, 5, 21, 15, 42, 49, 76000, tzinfo=datetime.timezone.utc), 'finishedAt': datetime.datetime(2024, 5, 21, 15, 42, 59, 961000, tzinfo=datetime.timezone.utc), 'status': 'SUCCEEDED', 'meta': {'origin': 'API', 'userAgent': 'ApifyClient/1.6.4 (darwin; Python/3.10.9); isAtHome/False'}, 'stats': {'inputBodyLen': 272, 'rebootCount': 0, 'restartCount': 0, 'durationMillis': 10376, 'resurrectCount': 0, 'runTimeSecs': 10.376, 'metamorph': 0, 'computeUnits': 0.0007205555555555556, 'memAvgBytes': 85954151.6507009, 'memMaxBytes': 120299520, 'memCurrentBytes': 0, 'cpuAvgUsage': 4.414258256217614, 'cpuMaxUsage': 86.54049032258064, 'cpuCurrentUsage': 0, 'netRxBytes': 137386, 'netTxBytes': 65678}, 'options': {'build': 'latest', 'timeoutSecs': 0, 'memoryMbytes': 256, 'diskMbytes': 512}, 'buildId': 'ozYdfwUm2sll1BJa3', 'exitCode': 0, 'defaultKeyValueStoreId': 'f3TA8lAYyHlQbLnWs', 'defaultDatasetId': 'L0kOhbifBprlUpgXj', 'defaultRequestQueueId': 'pZ2v5DbWw5xVJ7fKL', 'buildNumber': '0.0.272', 'containerUrl': 'https://qjuadtnkjopp.runs.apify.net', 'usage': {'ACTOR_COMPUTE_UNITS': 0.0007205555555555556, 'DATASET_READS': 0, 'DATASET_WRITES': 26, 'KEY_VALUE_STORE_READS': 1, 'KEY_VALUE_STORE_WRITES': 1, 'KEY_VALUE_STORE_LISTS': 0, 'REQUEST_QUEUE_READS': 0, 'REQUEST_QUEUE_WRITES': 0, 'DATA_TRANSFER_INTERNAL_GBYTES': 0, 'DATA_TRANSFER_EXTERNAL_GBYTES': 6.11674040555954e-05, 'PROXY_RESIDENTIAL_TRANSFER_GBYTES': 0, 'PROXY_SERPS': 0}, 'usageTotalUsd': 0.0004854557030333413, 'usageUsd': {'ACTOR_COMPUTE_UNITS': 0.0002882222222222222, 'DATASET_READS': 0, 'DATASET_WRITES': 0.00013000000000000002, 'KEY_VALUE_STORE_READS': 5e-06, 'KEY_VALUE_STORE_WRITES': 5e-05, 'KEY_VALUE_STORE_LISTS': 0, 'REQUEST_QUEUE_READS': 0, 'REQUEST_QUEUE_WRITES': 0, 'DATA_TRANSFER_INTERNAL_GBYTES': 0, 'DATA_TRANSFER_EXTERNAL_GBYTES': 1.223348081111908e-05, 'PROXY_RESIDENTIAL_TRANSFER_GBYTES': 0, 'PROXY_SERPS': 0}}\n"
     ]
    }
   ],
   "source": [
    "# print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "#     results.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>twitterUrl</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>...</th>\n",
       "      <th>entities</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isQuote</th>\n",
       "      <th>media</th>\n",
       "      <th>isConversationControlled</th>\n",
       "      <th>inReplyToId</th>\n",
       "      <th>conversationId</th>\n",
       "      <th>retweet</th>\n",
       "      <th>quoteId</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet</td>\n",
       "      <td>1790680160783446056</td>\n",
       "      <td>https://x.com/apify/status/1790680160783446056</td>\n",
       "      <td>https://twitter.com/apify/status/1790680160783...</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "      <td>HubSpot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'timestamps': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tweet</td>\n",
       "      <td>1791091457459134814</td>\n",
       "      <td>https://x.com/apify/status/1791091457459134814</td>\n",
       "      <td>https://twitter.com/apify/status/1791091457459...</td>\n",
       "      <td>Requests, BeautifulSoup, MechanicalSoup or Scr...</td>\n",
       "      <td>HubSpot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'timestamps': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tweet</td>\n",
       "      <td>1790015506600034541</td>\n",
       "      <td>https://x.com/apify/status/1790015506600034541</td>\n",
       "      <td>https://twitter.com/apify/status/1790015506600...</td>\n",
       "      <td>Building dozens of custom web scraping project...</td>\n",
       "      <td>HubSpot</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'timestamps': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tweet</td>\n",
       "      <td>1780994809752178788</td>\n",
       "      <td>https://x.com/apify/status/1780994809752178788</td>\n",
       "      <td>https://twitter.com/apify/status/1780994809752...</td>\n",
       "      <td>Our open-source web scraping library Crawlee h...</td>\n",
       "      <td>HubSpot</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'media': [{'display_url': 'pi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[https://pbs.twimg.com/media/GLddV2tXYAAl6om.jpg]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tweet</td>\n",
       "      <td>1778757027294072856</td>\n",
       "      <td>https://x.com/apify/status/1778757027294072856</td>\n",
       "      <td>https://twitter.com/apify/status/1778757027294...</td>\n",
       "      <td>Apify had the pleasure of hosting another @cze...</td>\n",
       "      <td>HubSpot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'media': [{'display_url': 'pi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[https://pbs.twimg.com/media/GK9qEGwWIAAAELf.j...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                   id                                             url  \\\n",
       "0  tweet  1790680160783446056  https://x.com/apify/status/1790680160783446056   \n",
       "1  tweet  1791091457459134814  https://x.com/apify/status/1791091457459134814   \n",
       "2  tweet  1790015506600034541  https://x.com/apify/status/1790015506600034541   \n",
       "3  tweet  1780994809752178788  https://x.com/apify/status/1780994809752178788   \n",
       "4  tweet  1778757027294072856  https://x.com/apify/status/1778757027294072856   \n",
       "\n",
       "                                          twitterUrl  \\\n",
       "0  https://twitter.com/apify/status/1790680160783...   \n",
       "1  https://twitter.com/apify/status/1791091457459...   \n",
       "2  https://twitter.com/apify/status/1790015506600...   \n",
       "3  https://twitter.com/apify/status/1780994809752...   \n",
       "4  https://twitter.com/apify/status/1778757027294...   \n",
       "\n",
       "                                                text   source  retweetCount  \\\n",
       "0  If you're new to using BeautifulSoup for web s...  HubSpot             0   \n",
       "1  Requests, BeautifulSoup, MechanicalSoup or Scr...  HubSpot             0   \n",
       "2  Building dozens of custom web scraping project...  HubSpot             2   \n",
       "3  Our open-source web scraping library Crawlee h...  HubSpot             3   \n",
       "4  Apify had the pleasure of hosting another @cze...  HubSpot             0   \n",
       "\n",
       "   replyCount  likeCount  quoteCount  ...  \\\n",
       "0           0          0           0  ...   \n",
       "1           0          1           0  ...   \n",
       "2           0          4           0  ...   \n",
       "3           0          7           0  ...   \n",
       "4           0          4           0  ...   \n",
       "\n",
       "                                            entities isRetweet isQuote  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'timestamps': ...     False   False   \n",
       "1  {'hashtags': [], 'symbols': [], 'timestamps': ...     False   False   \n",
       "2  {'hashtags': [], 'symbols': [], 'timestamps': ...     False   False   \n",
       "3  {'hashtags': [], 'media': [{'display_url': 'pi...     False   False   \n",
       "4  {'hashtags': [], 'media': [{'display_url': 'pi...     False   False   \n",
       "\n",
       "                                               media  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [https://pbs.twimg.com/media/GLddV2tXYAAl6om.jpg]   \n",
       "4  [https://pbs.twimg.com/media/GK9qEGwWIAAAELf.j...   \n",
       "\n",
       "   isConversationControlled inReplyToId conversationId retweet quoteId quote  \n",
       "0                     False         NaN            NaN     NaN     NaN   NaN  \n",
       "1                     False         NaN            NaN     NaN     NaN   NaN  \n",
       "2                     False         NaN            NaN     NaN     NaN   NaN  \n",
       "3                     False         NaN            NaN     NaN     NaN   NaN  \n",
       "4                     False         NaN            NaN     NaN     NaN   NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Create a DataFrame from the results\n",
    "# df = pd.DataFrame(results)\n",
    "\n",
    "# # Print the DataFrme\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/1260817619.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['id'] = out_data['id'].astype(str)\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/1260817619.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['Political Actor'] = political_actor\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/1260817619.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['originalTweet'] = out_data['text'].iloc[0]\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/1260817619.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data.drop(out_data.index[0], inplace=True, axis=0)\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/1260817619.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['text'] = out_data['text'].apply(clean_text)\n",
      "/var/folders/hf/1s_l6dt91218_yqmlwxj9pxm0000gn/T/ipykernel_57898/1260817619.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_data['text'] = out_data['text'].map(lambda x: x if x != '' else None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>Political Actor</th>\n",
       "      <th>originalTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1791091457459134814</td>\n",
       "      <td>https://x.com/apify/status/1791091457459134814</td>\n",
       "      <td>requests, beautifulsoup, mechanicalsoup or scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790015506600034541</td>\n",
       "      <td>https://x.com/apify/status/1790015506600034541</td>\n",
       "      <td>building dozens of custom web scraping project...</td>\n",
       "      <td>4</td>\n",
       "      <td>357</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1780994809752178788</td>\n",
       "      <td>https://x.com/apify/status/1780994809752178788</td>\n",
       "      <td>our opensource web scraping library crawlee ha...</td>\n",
       "      <td>7</td>\n",
       "      <td>827</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1778757027294072856</td>\n",
       "      <td>https://x.com/apify/status/1778757027294072856</td>\n",
       "      <td>apify had the pleasure of hosting another meet...</td>\n",
       "      <td>4</td>\n",
       "      <td>346</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1788825697227505811</td>\n",
       "      <td>https://x.com/apify/status/1788825697227505811</td>\n",
       "      <td>another important win for the web scraping ind...</td>\n",
       "      <td>8</td>\n",
       "      <td>605</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1782016934755676251</td>\n",
       "      <td>https://x.com/apify/status/1782016934755676251</td>\n",
       "      <td>when scraping websites, youre likely to encoun...</td>\n",
       "      <td>3</td>\n",
       "      <td>424</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1778393237226406110</td>\n",
       "      <td>https://x.com/apify/status/1778393237226406110</td>\n",
       "      <td>amazon is one of the largest and most complex ...</td>\n",
       "      <td>3</td>\n",
       "      <td>796</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1777672744617828826</td>\n",
       "      <td>https://x.com/apify/status/1777672744617828826</td>\n",
       "      <td>give your scraping skills a boost with crawlee...</td>\n",
       "      <td>2</td>\n",
       "      <td>298</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1776945013672288458</td>\n",
       "      <td>https://x.com/apify/status/1776945013672288458</td>\n",
       "      <td>use playwright with python to automate browser...</td>\n",
       "      <td>2</td>\n",
       "      <td>368</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1779119842450157980</td>\n",
       "      <td>https://x.com/apify/status/1779119842450157980</td>\n",
       "      <td>is it worth adding mechanicalsoup to your web ...</td>\n",
       "      <td>2</td>\n",
       "      <td>367</td>\n",
       "      <td>waraujo64</td>\n",
       "      <td>If you're new to using BeautifulSoup for web s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                             url  \\\n",
       "1   1791091457459134814  https://x.com/apify/status/1791091457459134814   \n",
       "2   1790015506600034541  https://x.com/apify/status/1790015506600034541   \n",
       "3   1780994809752178788  https://x.com/apify/status/1780994809752178788   \n",
       "4   1778757027294072856  https://x.com/apify/status/1778757027294072856   \n",
       "5   1788825697227505811  https://x.com/apify/status/1788825697227505811   \n",
       "6   1782016934755676251  https://x.com/apify/status/1782016934755676251   \n",
       "7   1778393237226406110  https://x.com/apify/status/1778393237226406110   \n",
       "8   1777672744617828826  https://x.com/apify/status/1777672744617828826   \n",
       "9   1776945013672288458  https://x.com/apify/status/1776945013672288458   \n",
       "10  1779119842450157980  https://x.com/apify/status/1779119842450157980   \n",
       "\n",
       "                                                 text  likeCount  viewCount  \\\n",
       "1   requests, beautifulsoup, mechanicalsoup or scr...          1        158   \n",
       "2   building dozens of custom web scraping project...          4        357   \n",
       "3   our opensource web scraping library crawlee ha...          7        827   \n",
       "4   apify had the pleasure of hosting another meet...          4        346   \n",
       "5   another important win for the web scraping ind...          8        605   \n",
       "6   when scraping websites, youre likely to encoun...          3        424   \n",
       "7   amazon is one of the largest and most complex ...          3        796   \n",
       "8   give your scraping skills a boost with crawlee...          2        298   \n",
       "9   use playwright with python to automate browser...          2        368   \n",
       "10  is it worth adding mechanicalsoup to your web ...          2        367   \n",
       "\n",
       "   Political Actor                                      originalTweet  \n",
       "1        waraujo64  If you're new to using BeautifulSoup for web s...  \n",
       "2        waraujo64  If you're new to using BeautifulSoup for web s...  \n",
       "3        waraujo64  If you're new to using BeautifulSoup for web s...  \n",
       "4        waraujo64  If you're new to using BeautifulSoup for web s...  \n",
       "5        waraujo64  If you're new to using BeautifulSoup for web s...  \n",
       "6        waraujo64  If you're new to using BeautifulSoup for web s...  \n",
       "7        waraujo64  If you're new to using BeautifulSoup for web s...  \n",
       "8        waraujo64  If you're new to using BeautifulSoup for web s...  \n",
       "9        waraujo64  If you're new to using BeautifulSoup for web s...  \n",
       "10       waraujo64  If you're new to using BeautifulSoup for web s...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# # Define a function to clean individual text entries\n",
    "# def clean_text(text):\n",
    "#     # Convert to lowercase\n",
    "#     text = text.lower()\n",
    "#     # Remove URLs\n",
    "#     text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "#     # Remove usernames\n",
    "#     text = re.sub(r'@\\w+', '', text)\n",
    "#     # Remove emojis\n",
    "#     text = re.sub(r'[^\\w\\s,]', '', text)\n",
    "#     # Remove hashtags\n",
    "#     text = re.sub(r'#\\S+', '', text)\n",
    "#     # Remove extra spaces\n",
    "#     text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "#     return text\n",
    "\n",
    "# def process_tweet_data(df, political_actor):\n",
    "    \n",
    "#     # Select specific columns\n",
    "#     out_data = df[['id', 'url', 'text', 'likeCount', 'viewCount']]\n",
    "    \n",
    "#     # Convert 'id' to string type\n",
    "#     out_data['id'] = out_data['id'].astype(str)\n",
    "    \n",
    "#     # Add a new column with a static value\n",
    "#     out_data['Political Actor'] = political_actor\n",
    "    \n",
    "#     # Store the first 'text' entry in a new column for all rows\n",
    "#     if not out_data.empty:\n",
    "#         out_data['originalTweet'] = out_data['text'].iloc[0]\n",
    "    \n",
    "#     # Drop the first row\n",
    "#     out_data.drop(out_data.index[0], inplace=True, axis=0)\n",
    "\n",
    "#     # clean text column\n",
    "#     out_data['text'] = out_data['text'].apply(clean_text)\n",
    "\n",
    "#     # remove na values in text column\n",
    "#     out_data['text'] = out_data['text'].map(lambda x: x if x != '' else None)\n",
    "#     out_data = out_data.dropna(subset=['text'])\n",
    "    \n",
    "#     # Return the first 10 rows of the DataFrame to check\n",
    "#     return out_data\n",
    "\n",
    "# # Example usage\n",
    "# # Load the dataset from a JSON file\n",
    "# file_path = '/Users/misanmeggison/Downloads/dataset_tweet-scraper_2024-05-16_18-43-56-243.json'\n",
    "# # df = pd.read_json(file_path)\n",
    "\n",
    "# # Process the data\n",
    "# processed_data = process_tweet_data(df, political_actor)\n",
    "# processed_data.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
