# -*- coding: utf-8 -*-
"""IREX_Sentiment_Analysis_v1_Preprocessing_sd.ipynb

Automatically generated by Colab.

"""
#install spacy before running


import pandas as pd
import re
import spacy
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer


# Load your dataset into a DataFrame
df = pd.read_excel('sentiment_beto_sample_bukele_v1.xlsx')
df.head()


# Download NLTK data files (only needed if not already downloaded)
nltk.download('punkt')
nltk.download('stopwords')

# Load the spaCy model for Spanish
nlp = spacy.load('es_core_news_sm')

# Initialize the Snowball stemmer for Spanish
stemmer = SnowballStemmer('spanish')

# Define a list of stopwords
stop_words = set(stopwords.words('spanish'))

# Function to preprocess text
def preprocess_text(text):
    # Remove special characters (keeping numbers) and convert to lowercase
    text = re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ0-9]', ' ', text)
    # Remove extra whitespaces
    text = re.sub(r'\s+', ' ', text)
    # Convert text to lowercase
    text = text.lower()
    # Tokenize the text
    tokens = word_tokenize(text)
    # Remove stopwords
    filtered_tokens = [token for token in tokens if token not in stop_words]
    # Reconstruct the text
    processed_text = ' '.join(filtered_tokens)
    return processed_text

# Function to apply lemmatization and stemming to text
def lemmatize_and_stem(text):
    # Lemmatize using spaCy
    doc = nlp(text)
    lemmatized_tokens = [token.lemma_ for token in doc]

    # Stem using NLTK SnowballStemmer
    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]

    # Reconstruct the text
    processed_text = ' '.join(stemmed_tokens)
    return processed_text

# Pipeline function to load data and apply preprocessing
def clean_pipeline(df):
    # Map sentiment classes to numerical labels
    sentiment_mapping = {'POS': 0, 'NEU': 1, 'NEG': 2}
    df['sentiment_numeric'] = df[label_column].map(sentiment_mapping)

    # Apply preprocessing, lemmatization, and stemming to the 'Text' column
    df['processed_text'] = df['Text'].apply(preprocess_text).apply(lemmatize_and_stem)

 
    return df



#Calling final dataframe with preproceesed
label_column= 'AP'
df = clean_pipeline(df)