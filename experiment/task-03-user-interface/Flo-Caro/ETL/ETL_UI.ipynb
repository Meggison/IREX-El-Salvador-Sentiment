{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL process previous to the build of the live user interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library, modules and token imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from apify_client import ApifyClient\n",
    "from tokens import APIFY_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIFY_ACTOR_ID = '61RPP7dywgiy0JPD0'\n",
    "\n",
    "TWEETS_COLUMNS_LIST = [\n",
    "    \"url\",\n",
    "    \"createdAt\",\n",
    "    \"id\",\n",
    "    \"isReply\",\n",
    "    \"inReplyToId\",\n",
    "    \"isRetweet\",\n",
    "    \"isQuote\",\n",
    "    \"viewCount\",\n",
    "    \"retweetCount\",\n",
    "    \"likeCount\",\n",
    "    \"replyCount\",\n",
    "    \"lang\",\n",
    "    \"author__createdAt\",\n",
    "    \"author__location\",\n",
    "    \"author__name\",\n",
    "    \"author__id\",\n",
    "    \"author__description\",\n",
    "    \"author__followers\",\n",
    "    \"author__verified\",\n",
    "    \"text\"\n",
    "]\n",
    "\n",
    "REMOVE_COLUMNS_COMMENTS = [\n",
    "    \"author__name\",\n",
    "    \"author__id\",\n",
    "    \"author__description\",\n",
    "]\n",
    "\n",
    "INT_COLUMNS = [\n",
    "    \"viewCount\",\n",
    "    \"retweetCount\",\n",
    "    \"likeCount\",\n",
    "    \"replyCount\",\n",
    "    \"author__followers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns have been pre-selected by the Data Collection team in order to source the Sentiment Analysis model exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apify Client Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ApifyClient(APIFY_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to extract the information using Apify Client, and convert it to a Pandas dataframe, based on an original Tweet by a political actor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_response(response):\n",
    "    \"\"\" Returns a flat dictionary with unnested values \"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"url\": response.get(\"url\"),\n",
    "        \"createdAt\": pd.to_datetime(response.get(\"createdAt\")),\n",
    "        \"id\": response.get(\"id\"),\n",
    "        \"isReply\": response.get(\"isReply\"),\n",
    "        \"inReplyToId\": response.get(\"inReplyToId\", None), # Uses None if inReply is false\n",
    "        \"isRetweet\": response.get(\"isRetweet\"),\n",
    "        \"isQuote\": response.get(\"isQuote\"),\n",
    "        \"viewCount\": response.get(\"viewCount\"),\n",
    "        \"retweetCount\": response.get(\"retweetCount\"),\n",
    "        \"likeCount\": response.get(\"likeCount\"),\n",
    "        \"replyCount\": response.get(\"replyCount\"),\n",
    "        \"lang\": response.get(\"lang\"),\n",
    "        \"author__createdAt\": pd.to_datetime(response[\"author\"].get(\"createdAt\")),\n",
    "        \"author__location\": response[\"author\"].get(\"location\"),\n",
    "        \"author__name\": response[\"author\"].get(\"name\"),\n",
    "        \"author__id\": response[\"author\"].get(\"id\"),\n",
    "        \"author__description\": response[\"author\"].get(\"description\"),\n",
    "        \"author__followers\": response[\"author\"].get(\"followers\"),\n",
    "        \"author__verified\": response[\"author\"].get(\"isVerified\"),\n",
    "        \"text\": response.get(\"text\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_tweet_dataframe(url):\n",
    "    \"\"\" Given a tweet URL, returns a dataframe for it \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if 'x.com' not in url and 'twitter.com' not in url:\n",
    "        return {'error': 'Input is not a tweet URL'}\n",
    "\n",
    "    run_input = {\n",
    "        \"startUrls\": [url],\n",
    "    }\n",
    "\n",
    "    run = client.actor(APIFY_ACTOR_ID).call(run_input=run_input)\n",
    "\n",
    "    response = [dictionary for dictionary in client.dataset(run[\"defaultDatasetId\"]).iterate_items()][0]\n",
    "\n",
    "    flattened_data = flatten_response(response)\n",
    "\n",
    "    # Convert the flattened dictionary to a DataFrame\n",
    "    df = pd.DataFrame([flattened_data], columns=TWEETS_COLUMNS_LIST)\n",
    "\n",
    "    # Convert columns to integers, handling None/NaN appropriately\n",
    "    df[INT_COLUMNS] = df[INT_COLUMNS].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_dataframe(url):\n",
    "    \"\"\" Given a tweet URL, returns a dataframe for the comments related to that tweet \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if 'x.com' not in url and 'twitter.com' not in url:\n",
    "        return {'error': 'Input is not a tweet URL'}\n",
    "\n",
    "    one_tweet_id = str(url.split('/')[-1])\n",
    "\n",
    "    run_input_comment = {\n",
    "        \"conversationIds\": [one_tweet_id],\n",
    "        \"maxItems\": 300\n",
    "    }\n",
    "\n",
    "    run_comment = client.actor(APIFY_ACTOR_ID).call(run_input=run_input_comment)\n",
    "\n",
    "    response_comment = [dictionary for dictionary in client.dataset(run_comment[\"defaultDatasetId\"]).iterate_items()]\n",
    "\n",
    "    flattened_responses = [flatten_response(response) for response in response_comment]\n",
    "\n",
    "    # Keep only the selected columns\n",
    "    include_columns = [column for column in TWEETS_COLUMNS_LIST if column not in REMOVE_COLUMNS_COMMENTS]\n",
    "\n",
    "    # Convert the flattened dictionary to a DataFrame\n",
    "    df =  pd.DataFrame(flattened_responses, columns=include_columns)\n",
    "\n",
    "    # Convert columns to integers, handling None/NaN appropriately\n",
    "    df[INT_COLUMNS] = df[INT_COLUMNS].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to produce 5 Datasets, from different political actors, to be used as demo examples. Sentiment Analysis to be added later:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets = {\n",
    "    'nayib_bukele': 'https://x.com/nayibbukele/status/1788014378324754680',\n",
    "    'walter_araujo': 'https://twitter.com/waraujo64/status/1782761311526391916',\n",
    "    'marcelo_larin': 'https://twitter.com/MarceloLarin1/status/1774118316648599645',\n",
    "    'gustavo_villatoro': 'https://x.com/Vi11atoro/status/1767373813526737223',\n",
    "    'suecy_callejas_estrada': 'https://x.com/suecallejas/status/1786430963947335686'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the tweets to parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for actor, url in sample_tweets.items():\n",
    "    main_df = main_tweet_dataframe(url)\n",
    "    comments_df = comments_dataframe(url)\n",
    "    main_file_name = f\"{actor}_tweet.parquet\"\n",
    "    main_df.to_parquet(main_file_name, engine=\"pyarrow\", use_deprecated_int96_timestamps=True)\n",
    "    comments_file_name = f\"{actor}_tweet_comments.parquet\"\n",
    "    comments_df.to_parquet(comments_file_name, engine=\"pyarrow\", use_deprecated_int96_timestamps=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OmdenaIrex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
